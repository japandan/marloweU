#'Deletes all information in the database candidate in preparation of data re-population.
#'This is a modified version for testing with UniProt data.
#'
#'`delete_database` Drop the schema in preparation of data re-population.
#'
#'@param conn database connection values to create a MySQL connection
#'@param force When true don't prompt the user to verify if they want to delete the sample
#'
#'@return true when successful
#'@importFrom assertthat assert_that
#'@importFrom DBI dbExecute dbDisconnect dbConnect
#'@importFrom RMariaDB MariaDB
#'
#'@author Dustin Crockett
#'@author Daniel Vogel
#'
#'@export
library( parallel )
library( DBI )
library( magrittr )
library(MakeSearchSim)
library(CandidateSearchDatabase)
library(OrgIDPipeline)

# MySQL connection credentials.  These need to match your installation
conn_list <- list(
  "dbname"= "candidate",
  "host" = "localhost",
  "port" = 3306,
  "user" = "msdba",
  "password" = "MassSpec2021!"
)

library(tidyverse)
library(magrittr)

delete_database <- function(conn, force=F) {
  #validate the the user really wants to delete the database
  if(!is.logical(force) | !isTRUE(force)) {
    response <- readline(prompt=paste0("Are you sure you want to delete database?"))
    if(!toupper(response) == "Y" & !toupper(response) == "YES" ) {
      return(0)
    }
  }

  #validate the conn list
  # verify that the conn is a list
  assertthat::assert_that(is.list(conn),
                          msg = "conn is not a list. Make sure conn is a list.")
  # verify that conn has the correct fields
  assertthat::assert_that("dbname" %in% names(conn),
                          msg = "dbname is missing from the list conn")
  assertthat::assert_that("host" %in% names(conn),
                          msg = "host is missing from the list conn")
  assertthat::assert_that("port" %in% names(conn),
                          msg = "port is missing from the list conn")
  assertthat::assert_that("user" %in% names(conn),
                          msg = "user is missing from the list conn")
  assertthat::assert_that("password" %in% names(conn),
                          msg = "password is missing from the list conn")

  con <- dbConnect(RMariaDB::MariaDB(),
                   host = conn$host,
                   port = conn$port,
                   user = conn$user,
                   password = conn$password)

  #drop the schema
 DBI:: dbExecute(con, "drop database if exists candidate")

  dbDisconnect(con)
  return(T)
}

#'Creates all tables and database code needed for this package
#'
#'`create_datamodel` Creates all tables and database code needed for this package.
#'
#'@param conn database connection values to create a MySQL connection
#'@param large_storage_found when True use the large_storage location for peptide_map when
#' false place peptide map with the rest of the database
#'@param large_storage The storage location of the large storage
#'@param max_peptide_length the maximum character length of peptides to be imported
#'
#'@return true when successful
#'@importFrom assertthat assert_that
#'@importFrom DBI dbExecute dbDisconnect dbConnect
#'@importFrom RMariaDB MariaDB
#'
#'@author Dustin Crockett
#'
#'@export
create_datamodel <- function(conn,large_storage_found=F, large_storage=NULL, max_peptide_length=250) {
  #validate the conn list
  # verify that the conn is a list
  assertthat::assert_that(is.list(conn),
                          msg = "conn is not a list. Make sure conn is a list.")
  # verify that conn has the correct fields
  assertthat::assert_that("dbname" %in% names(conn),
                          msg = "dbname is missing from the list conn")
  assertthat::assert_that("host" %in% names(conn),
                          msg = "host is missing from the list conn")
  assertthat::assert_that("port" %in% names(conn),
                          msg = "port is missing from the list conn")
  assertthat::assert_that("user" %in% names(conn),
                          msg = "user is missing from the list conn")
  assertthat::assert_that("password" %in% names(conn),
                          msg = "password is missing from the list conn")

  con <- DBI::dbConnect(RMariaDB::MariaDB(),
                   host = conn$host,
                   port = conn$port,
                   user = conn$user,
                   password = conn$password)

  #create the schema for the datamodel to live in
  DBI::dbExecute(con, 'create database candidate CHARACTER SET latin1 COLLATE latin1_swedish_ci')
  #DBI::dbExecute(con, 'create database candidate CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci')
  DBI::dbDisconnect(con)

  con <- DBI::dbConnect(RMariaDB::MariaDB(),
                   dbname = conn$dbname,
                   host = conn$host,
                   port = conn$port,
                   user = conn$user,
                   password = conn$password)

  DBI::dbExecute(con, 'create table candidate.genus ( `id` int2 unsigned primary key auto_increment,
            `name` varchar(250) not null,
            constraint genus_name_un unique (name) )')

  DBI::dbExecute(con, 'create table candidate.species ( `id` int2 unsigned primary key auto_increment,
            `name` varchar(250) not null,
            `genus_id` int2 unsigned not null,
            constraint species_name_genus_un unique (genus_id, name) )')

  DBI::dbExecute(con, 'create table candidate.organisms ( `id` int2 unsigned primary key auto_increment,
            `kegg_id` varchar(25) not null,
            `name` varchar(250) not null,
            kegg_org_code varchar(25) not null,
            `species_id` int2 unsigned not null,
            peptide_count int unsigned not null,
            protein_count int2 unsigned not null,
            strong_peptide_count int unsigned null,
            taxon_id int unsigned null,
            constraint organisms_kegg_id_un unique (kegg_id) )')

  DBI::dbExecute(con, 'create table candidate.overlap_coefficient ( organism_id_i int2 unsigned,
            organism_id_j int2 unsigned,
            coefficient float(23) not null,
            jaccard_index float(23) not null,
            match_count int3 unsigned not null,
            strong_coefficient float(23) not null,
            strong_jaccard_index float(23) not null,
            strong_match_count int3 unsigned not null,
            primary key (organism_id_i, organism_id_j))')

  DBI::dbExecute(con, 'create table candidate.sequences ( `id` int unsigned primary key auto_increment,
            sequence_hash char(64) not null,
            `sequence` text not null,
            `length` int unsigned not null,
            constraint sequence_hash_un unique (sequence_hash) )')

  DBI::dbExecute(con, 'create table candidate.proteins ( `id` int unsigned primary key auto_increment,
            organism_id int2 unsigned not null,
            protein_kegg_id varchar(25) not null,
            name varchar(255),
            definition varchar(4000),
            orthology varchar(4000),
            position varchar(4000),
            motif varchar(4000),
            sequence_id int unsigned not null,
            sequence_count_in_org int2 unsigned not null,
            constraint proteins_kegg_id_un unique (protein_kegg_id, organism_id, sequence_id) )')

  DBI::dbExecute(con, 'create table candidate.protein_pathways ( protein_id int unsigned,
            short_path varchar(25),
            description varchar(4000),
            primary key (protein_id, short_path) )')

  DBI::dbExecute(con, 'create table candidate.protein_modules ( protein_id int unsigned,
            module_core varchar(25),
            description varchar(4000),
            primary key (protein_id, module_core) )')

  DBI::dbExecute(con, 'create table candidate.dblinks ( id int unsigned primary key auto_increment,
            `database` varchar(25),
            constraint dblinks_database_un unique (`database`) )')

  DBI::dbExecute(con, 'create table candidate.protein_to_dblinks ( protein_id int unsigned,
            dblink_id int unsigned,
            `key` varchar(500),
            primary key (protein_id, dblink_id) )')

  DBI::dbExecute(con, 'create table candidate.enzymes ( id int unsigned primary key auto_increment,
            `key` varchar(250) not null,
            protein_id int unsigned,
            description varchar(4000))')

  DBI::dbExecute(con, 'create table candidate.sequence_to_peptides ( sequence_id int unsigned,
            peptide_id int unsigned,
            total_count int2 unsigned,
            primary key (peptide_id, sequence_id) )')

  DBI::dbExecute(con, 'create table candidate.sequence_to_peptides_filtered ( sequence_id int unsigned,
            peptides_filtered_id int unsigned,
            primary key (peptides_filtered_id, sequence_id) )')

  DBI::dbExecute(con, paste0('create table candidate.peptides ( id int unsigned primary key auto_increment,
                        peptide_original varchar(', max_peptide_length, ') not null,
                        mass numeric(9,4) not null,
                        `length` int2 unsigned not null,
                        peptide_substitution varchar(', max_peptide_length, ') not null,
                        organism_count int2 unsigned not null default 0,
                        constraint peptides_peptide_un unique (peptide_original) )'))

  DBI::dbExecute(con, 'create table candidate.peptides_filtered ( id int unsigned primary key auto_increment,
            peptide_hash char(64) not null,
            peptide text not null,
            mass numeric(13,4) not null,
            `length` int unsigned not null,
            constraint peptides_hash_un unique (peptide_hash) )')

  DBI::dbExecute(con, 'create table candidate.organisms_to_peptides ( organism_id int2 unsigned,
            peptide_id int unsigned,
            total_count int2 unsigned,
            primary key (organism_id, peptide_id) )')

  DBI::dbExecute(con, 'create table candidate.strong_peptides ( peptide_id int unsigned,
            strong_genus_id int2 unsigned,
            strong_percent float(23) not null,
            second_genus_id int2 unsigned,
            second_percent float(23),
            primary key (peptide_id, strong_genus_id) )')

  DBI::dbExecute(con, 'create table candidate.peptide_tags ( id int3 unsigned primary key auto_increment,
            peptide_tag char(5) not null,
            constraint peptide_tags_peptide_tag_un unique (peptide_tag) )')

  if(large_storage_found) {
    DBI::dbExecute(con,paste0("create table candidate.peptide_map ( peptide_tag_id int3 unsigned,
                         peptide_id int unsigned,
                         first_location int1 unsigned not null,
                         max_characters_left int1 unsigned not null,
                         count_in_peptide int1 unsigned not null,
                         mass numeric(9,4) not null,
                         primary key (peptide_tag_id, peptide_id)) DATA DIRECTORY='", large_storage ,"'"))

  } else {
    DBI::dbExecute(con, "create table candidate.peptide_map ( peptide_tag_id int3 unsigned,
              peptide_id int unsigned,
              first_location int1 unsigned not null,
              max_characters_left int1 unsigned not null,
              count_in_peptide int1 unsigned not null,
              mass numeric(9,4) not null,
              primary key (peptide_tag_id, peptide_id)) ")
  }

  DBI::dbExecute(con, 'create table candidate.sample_sets ( id int unsigned primary key auto_increment,
            `name` varchar(255) not null,
            constraint sample_sets_name_un unique (`name`) )')

  DBI::dbExecute(con, paste0('create table candidate.samples ( id int unsigned primary key auto_increment,
                        sample_set_id int unsigned not null,
                        sample_name varchar(250) ,
                        peptide varchar(', max_peptide_length, ') not null,
                        peptide_tag character(5) not null,
                        characters_left int2 unsigned not null,
                        mass numeric(9,4) not null,
                        min_mass numeric(9,4) not null,
                        max_mass numeric(9,4) not null,
                        min_mass_ppm int2 not null,
                        max_mass_ppm int2 not null,
                        weight float(23) not null,
                        sample_tag_id varchar(500),
                        scan_num numeric(9,4),
                        lc_threshold numeric(9,4),
                        original_peptide varchar(4000) not null)'))

  DBI::dbExecute(con, 'create table candidate.samples_to_peptides ( sample_id int unsigned,
            peptide_id int unsigned,
            first_location int2 unsigned not null,
            count_in_peptide int1 unsigned not null,
            organism_count int unsigned not null,
            primary key (sample_id, peptide_id))')

  DBI::dbExecute(con, 'create table candidate.samples_peptide_to_organisms ( sample_id int unsigned,
            peptide_id int unsigned,
            organism_id int2 unsigned,
            is_strong_peptide int1 unsigned,
            total_count int2 unsigned,
            primary key (sample_id, peptide_id, organism_id))')

  DBI::dbExecute(con, 'create table candidate.taxons ( taxon_id int unsigned not null,
			parent_taxon_id int unsigned null,
            `rank` varchar(750) null,
            embl_code varchar(750) null,
            division_id int unsigned null,
            inherited_div_flag int null,
            genetic_code_id int unsigned null,
            inherited_Gc_flag int null,
            mitochondrial_genetic_code_id int unsigned null,
            inherited_MGC_flag int null,
            GenBank_hidden_flag int null,
            hidden_subtree_root_flag int null,
            comments varchar(750) null,
            plastid_genetic_code_id int unsigned null,
            inherited_PGC_flag int  null,
            specified_species int unsigned null,
            hydrogenosome_genetic_code_id int  null,
            inherited_HCG_flag int  null,
            primary key(taxon_id))')

  DBI::dbExecute(con, 'create table candidate.taxon_lineages ( taxon_id int unsigned not null,
                                          taxon_name varchar(750) null,
                                          taxon_rank varchar(750) null,
                                          superkingdom int unsigned null,
                                          superkingdom_name varchar(750) null,
                                          kingdom int unsigned null,
                                          kingdom_name varchar(750) null,
                                          subkingdom int unsigned null,
                                          subkingdom_name varchar(750) null,
                                          superphylum int unsigned null,
                                          superphylum_name varchar(750) null,
                                          phylum int unsigned null,
                                          phylum_name varchar(750) null,
                                          subphylum int unsigned null,
                                          subphylum_name varchar(750) null,
                                          superclass int unsigned null,
                                          superclass_name varchar(750) null,
                                          class int unsigned null,
                                          class_name varchar(750) null,
                                          subclass int unsigned null,
                                          subclass_name varchar(750) null,
                                          infraclass int unsigned null,
                                          infraclass_name varchar(750) null,
                                          cohort int unsigned null,
                                          cohort_name varchar(750) null,
                                          superorder int unsigned null,
                                          superorder_name varchar(750) null,
                                          `order` int unsigned null,
                                          order_name varchar(750) null,
                                          suborder int unsigned null,
                                          suborder_name varchar(750) null,
                                          infraorder int unsigned null,
                                          infraorder_name varchar(750) null,
                                          parvorder int unsigned null,
                                          parvorder_name varchar(750) null,
                                          superfamily int unsigned null,
                                          superfamily_name varchar(750) null,
                                          family int unsigned null,
                                          family_name varchar(750) null,
                                          subfamily int unsigned null,
                                          subfamily_name varchar(750) null,
                                          tribe int unsigned null,
                                          tribe_name varchar(750) null,
                                          subtribe int unsigned null,
                                          subtribe_name varchar(750) null,
                                          genus int unsigned null,
                                          genus_name varchar(750) null,
                                          subgenus int unsigned null,
                                          subgenus_name varchar(750) null,
                                          `section` int unsigned null,
                                          section_name varchar(750) null,
                                          subsection int unsigned null,
                                          subsection_name varchar(750) null,
                                          series int unsigned null,
                                          series_name varchar(750) null,
                                          species_group int unsigned null,
                                          species_group_name varchar(750) null,
                                          species_subgroup int unsigned null,
                                          species_subgroup_name varchar(750) null,
                                          species int unsigned null,
                                          species_name varchar(750) null,
                                          subspecies int unsigned null,
                                          subspecies_name varchar(750) null,
                                          varietas int unsigned null,
                                          varietas_name varchar(750) null,
                                          forma int unsigned null,
                                          forma_name varchar(750) null)')


  DBI::dbExecute(con, 'create table candidate.taxon_names ( taxon_id int unsigned not null,
            name_txt varchar(750) null,
            unique_name varchar(750) null,
            name_class varchar(750) null)')

  DBI::dbExecute(con, 'alter table candidate.taxon_lineages add foreign key (taxon_id) references candidate.taxons (taxon_id)')

  DBI::dbExecute(con, 'alter table candidate.taxon_names add foreign key (taxon_id) references candidate.taxons (taxon_id)')

  DBI::dbExecute(con, 'alter table candidate.species add foreign key (genus_id) references candidate.genus (`id`)')

  DBI::dbExecute(con, 'alter table candidate.samples add foreign key (sample_set_id) references candidate.sample_sets (`id`)')

  DBI::dbExecute(con, 'alter table candidate.samples_to_peptides add foreign key (sample_id) references candidate.samples (`id`)')

  DBI::dbExecute(con, 'alter table candidate.samples_to_peptides add foreign key (peptide_id) references candidate.peptides (`id`)')

  DBI::dbExecute(con, 'alter table candidate.samples_peptide_to_organisms add foreign key (sample_id) references candidate.samples (`id`)')

  DBI::dbExecute(con, 'alter table candidate.samples_peptide_to_organisms add foreign key (peptide_id) references candidate.peptides (`id`)')

  DBI::dbExecute(con, 'alter table candidate.samples_peptide_to_organisms add foreign key (organism_id) references candidate.organisms (`id`)')

  DBI::dbExecute(con, 'alter table candidate.organisms add foreign key (species_id) references candidate.species (`id`)')

  DBI::dbExecute(con, 'alter table candidate.organisms add foreign key (taxon_id) references candidate.taxons (taxon_id)')

  DBI::dbExecute(con, 'alter table candidate.overlap_coefficient add foreign key (organism_id_i) references candidate.organisms (`id`)')

  DBI::dbExecute(con, 'alter table candidate.overlap_coefficient add foreign key (organism_id_j) references candidate.organisms (`id`)')

  DBI::dbExecute(con, 'alter table candidate.proteins add foreign key (organism_id) references candidate.organisms (`id`)')

  DBI::dbExecute(con, 'alter table candidate.organisms_to_peptides add foreign key (peptide_id) references candidate.peptides (`id`)')

  DBI::dbExecute(con, 'alter table candidate.organisms_to_peptides add foreign key (organism_id) references candidate.organisms (`id`)')

  DBI::dbExecute(con, 'alter table candidate.proteins add foreign key (sequence_id) references candidate.sequences (`id`)')

  DBI::dbExecute(con, 'alter table candidate.protein_pathways add foreign key (protein_id) references candidate.proteins (`id`)')

  DBI::dbExecute(con, 'alter table candidate.protein_modules add foreign key (protein_id) references candidate.proteins (`id`)')

  DBI::dbExecute(con, 'alter table candidate.protein_to_dblinks add foreign key (protein_id) references candidate.proteins (`id`)')

  DBI::dbExecute(con, 'alter table candidate.protein_to_dblinks add foreign key (dblink_id) references candidate.dblinks (`id`)')

  DBI::dbExecute(con, 'alter table candidate.enzymes add foreign key (protein_id) references candidate.proteins (`id`)')

  DBI::dbExecute(con, 'alter table candidate.sequence_to_peptides add foreign key (sequence_id) references candidate.sequences (`id`)')

  DBI::dbExecute(con, 'alter table candidate.sequence_to_peptides add foreign key (peptide_id) references candidate.peptides (`id`)')

  DBI::dbExecute(con, 'alter table candidate.sequence_to_peptides_filtered add foreign key (sequence_id) references candidate.sequences (`id`)')

  DBI::dbExecute(con, 'alter table candidate.sequence_to_peptides_filtered add foreign key (peptides_filtered_id) references candidate.peptides_filtered (`id`)')

  DBI::dbExecute(con, 'alter table candidate.strong_peptides add foreign key (peptide_id) references candidate.peptides (`id`)')

  DBI::dbExecute(con, 'alter table candidate.strong_peptides add foreign key (strong_genus_id) references candidate.genus (`id`)')

  DBI::dbExecute(con, 'alter table candidate.strong_peptides add foreign key (second_genus_id) references candidate.genus (`id`)')

  DBI::dbExecute(con, 'alter table candidate.peptide_map add foreign key (peptide_tag_id) references candidate.peptide_tags (`id`)')

  DBI::dbExecute(con, 'alter table candidate.peptide_map add foreign key (peptide_id) references candidate.peptides (`id`)')

  DBI::dbExecute(con, 'create table candidate.upload_proteins ( protein_id varchar(4000) null,
            `name` varchar(4000) null,
            definition varchar(4000) null,
            orthology varchar(4000) null,
            position varchar(4000) null,
            motif varchar(4000) null,
            aaseq text null,
            sequence_id int unsigned)')

  DBI::dbExecute(con, paste0('create table candidate.upload_peptides ( protein_id varchar(25) null,
                        peptide varchar(', max_peptide_length, ') null,
                        mass numeric(9,4) null,
                        peptide_id int unsigned) ENGINE = MEMORY'))

  DBI::dbExecute(con, 'create table candidate.upload_filtered_peptides ( protein_id varchar(4000) null,
            peptide varchar(20000) null,
            mass numeric(13,4) null)')

  DBI::dbExecute(con, 'create table candidate.upload_pathways ( protein_id varchar(4000) null,
            short_path varchar(4000) null,
            description varchar(4000) null )')

  DBI::dbExecute(con, 'create table candidate.upload_organism ( organism varchar(4000) null,
            kegg_id varchar(4000) null,
            letter_code varchar(4000) null,
            genus varchar(4000) null,
            species varchar(4000) null )')

  DBI::dbExecute(con, 'create table candidate.upload_module ( protein_id varchar(4000) null,
            module_code varchar(4000) null,
            description varchar(4000) null )')

  DBI::dbExecute(con, 'create table candidate.upload_enzymes ( protein_id varchar(4000) null,
            Enzyme varchar(4000) null,
            description varchar(4000) null )')

  DBI::dbExecute(con, 'create table candidate.upload_db_links ( protein_id varchar(4000) null,
            `database` varchar(4000) null,
            `id` varchar(4000) null )')

  DBI::dbExecute(con, 'create table candidate.upload_samples (
            original_peptide varchar(4000),
            Pep_mass numeric(13,4),
            min_mass numeric(13,4),
            max_mass numeric(13,4),
            min_mass_ppm int,
            max_mass_ppm int,
            sample_tag_id varchar(500),
            tag varchar(255),
            scan_num numeric(13,4),
            LC_threshold numeric(13,4),
            Weight numeric(9,5) )')

  #define views
  DBI::dbExecute(con, 'create or replace
                      	view candidate.taxon_lineages_ids as
                      select taxon_id, taxon_name, taxon_rank,superkingdom,kingdom,subkingdom,superphylum,phylum,subphylum ,
                                  superclass ,class , subclass ,infraclass ,cohort,superorder,`order`,suborder,infraorder,parvorder,superfamily,
                                  family,subfamily, tribe,subtribe,genus,subgenus,`section`,subsection,series,species_group,species_subgroup,
                                  species,subspecies,varietas,forma from candidate.taxon_lineages ')

  DBI::dbExecute(con, 'create or replace
                      	view candidate.taxon_lineages_names as
                      select taxon_id, taxon_name, taxon_rank,superkingdom_name superkingdom,kingdom_name kingdom,subkingdom_name subkingdom,
                      			superphylum_name superphylum,phylum_name phylum,subphylum_name subphylum,superclass_name superclass,
                      			class_name class, subclass_name subclass,infraclass_name infraclass,cohort_name cohort,superorder_name superorder,
                      			order_name "order",suborder_name suborder,infraorder_name infraorder,parvorder_name parvorder,
                      			superfamily_name superfamily,family_name family,subfamily_name subfamily, tribe_name tribe,subtribe_name subtribe,
                      			genus_name genus,subgenus_name subgenus,section_name "section",subsection_name subsection,series_name series,
                      			species_group_name species_group,species_subgroup_name species_subgroup,species_name species,
                      			subspecies_name subspecies,varietas_name varietas,forma_name forma from candidate.taxon_lineages ')


  DBI::dbDisconnect(con)
  return(T)
}

#'Overwrites all data in the upload tables with the data from this list of dataframes
#'This method is multi-threaded and will spawn off two threads that will upload
#'separate parts of the organism into the database at the same time.
#'
#'`upload_organism` Creates all tables and database code needed for this package.
#'
#'@param conn database connection values to create a MySQL connection
#'@param organism a list of dataframes that contains all information for one organism in the KEGG
#'@param max_peptide_length the maximum character length of peptides to be imported
#'
#'@importFrom assertthat assert_that
#'@importFrom parallel parLapply makeCluster clusterEvalQ clusterExport stopCluster
#'
#'@author Dustin Crockett
#'
#'@export
upload_organism <- function(conn, organism, max_peptide_length) {
  start_time = Sys.time()

  #validate the conn list
  # verify that the conn is a list
  assertthat::assert_that(is.list(conn),
                          msg = "conn is not a list. Make sure conn is a list.")
  # verify that conn has the correct fields
  assertthat::assert_that("dbname" %in% names(conn),
                          msg = "dbname is missing from the list conn")
  assertthat::assert_that("host" %in% names(conn),
                          msg = "host is missing from the list conn")
  assertthat::assert_that("port" %in% names(conn),
                          msg = "port is missing from the list conn")
  assertthat::assert_that("user" %in% names(conn),
                          msg = "user is missing from the list conn")
  assertthat::assert_that("password" %in% names(conn),
                          msg = "password is missing from the list conn")

  # verify that the organism is a list
  assertthat::assert_that(is.list(organism),
                          msg = "organism is not a list. Make sure organism is a list.")
  # verify that organism has the correct fields
  assertthat::assert_that("organism" %in% names(organism),
                          msg = "organism dataframe missing from the list organism")
  assertthat::assert_that(is.data.frame(organism$organism),
                          msg = "organism is not a dataframe")
  assertthat::assert_that("protein" %in% names(organism),
                          msg = "protein dataframe missing from the list organism")
  assertthat::assert_that(is.data.frame(organism$protein),
                          msg = "protein is not a dataframe")
  assertthat::assert_that("db_links" %in% names(organism),
                          msg = "DB_links dataframe missing from the list organism")
  assertthat::assert_that(is.data.frame(organism$db_links),
                          msg = "db_links is not a dataframe")
  assertthat::assert_that("peptides" %in% names(organism),
                          msg = "peptides dataframe missing from the list organism")
  assertthat::assert_that(is.data.frame(organism$peptides),
                          msg = "peptides is not a dataframe")

  #verify that the field organism has the correct columns
  assertthat::assert_that("organism" %in% colnames(organism$organism),
                          msg = "organism column missing from organism")
  assertthat::assert_that("kegg_id" %in% colnames(organism$organism),
                          msg = "kegg_id column missing from organism")
  assertthat::assert_that("letter_code" %in% colnames(organism$organism),
                          msg = "letter_code column missing from organism")
  assertthat::assert_that("genus" %in% colnames(organism$organism),
                          msg = "genus column missing from organism")
  assertthat::assert_that("species" %in% colnames(organism$organism),
                          msg = "species column missing from organism")


  #now that we have verified that this file will work, lets add some logging to the standard output
  cat(paste0("Started processing ", organism$organism$kegg_id[1] ," with ", nrow(organism$protein), " proteins, ", nrow(organism$enzyme), " enzymes, ", nrow(organism$db_links), " db_links, and ", nrow(organism$peptides), " peptides\n"))

  range_test <-  c(1,2)

  cl <- makeCluster(2)
  ## A bootstrapping example, which can be done in many ways:
  clusterEvalQ(cl, {
    ## set up each worker.
    library(DBI)
    library(RMariaDB)
    NULL
  })

    full_result <- parLapply("cl"=cl, "X" = range_test, "fun" = upload_partial, chunk.size = 1, conn= conn, max_peptide_length = max_peptide_length, organism = organism)

  stopCluster(cl)

  stop_time <- Sys.time()
  diff_time <- formatC(as.numeric(stop_time, units = "secs") - as.numeric(start_time, units = "secs"), digits=1, format= "f")
  cat(paste0("upload of ", full_result[1], " and ", full_result[2], " total time took ", diff_time, " seconds\n"))
}

#'A helper method that allows for multi-threading of organism uploading
#'This is an internal method used by upload_organism and requires
#'the organism list of dataframes and conn list of connection information
#'to be passed into it through.  This method can be called two different
#'times with a 1 or a 2 as the in_set value to upload the two halves of
#'the organism.
#'
#'@param in_set a number that defines which step of logic to use
#'@param conn database connection values to create a MySQL connection
#'@param max_peptide_length the maximum character length of peptides to be imported
#'@param organism a list of dataframes that contains all informations for one organism in the KEGG
#'
#'@return string describing how long in seconds that it took for the step to complete
#'@importFrom DBI dbExecute dbWriteTable dbDisconnect dbConnect
#'@importFrom RMariaDB MariaDB
#'
#'@author Dustin Crockett
upload_partial <- function(in_set, conn, max_peptide_length, organism) {
  start_time = Sys.time()

  #validate the conn list
  # verify that the conn is a list
  assertthat::assert_that(is.list(conn),
                          msg = "conn is not a list. Make sure conn is a list.")
  # verify that conn has the correct fields
  assertthat::assert_that("dbname" %in% names(conn),
                          msg = "dbname is missing from the list conn")
  assertthat::assert_that("host" %in% names(conn),
                          msg = "host is missing from the list conn")
  assertthat::assert_that("port" %in% names(conn),
                          msg = "port is missing from the list conn")
  assertthat::assert_that("user" %in% names(conn),
                          msg = "user is missing from the list conn")
  assertthat::assert_that("password" %in% names(conn),
                          msg = "password is missing from the list conn")

  # verify that the organism is a list
  assertthat::assert_that(is.list(organism),
                          msg = "organism is not a list. Make sure organism is a list.")
  # verify that organism has the correct fields
  assertthat::assert_that("organism" %in% names(organism),
                          msg = "organism dataframe missing from the list organism")
  assertthat::assert_that(is.data.frame(organism$organism),
                          msg = "organism is not a dataframe")
  assertthat::assert_that("protein" %in% names(organism),
                          msg = "protein dataframe missing from the list organism")
  assertthat::assert_that(is.data.frame(organism$protein),
                          msg = "protein is not a dataframe")
  assertthat::assert_that("db_links" %in% names(organism),
                          msg = "DB_links dataframe missing from the list organism")
  assertthat::assert_that(is.data.frame(organism$db_links),
                          msg = "db_links is not a dataframe")
  assertthat::assert_that("peptides" %in% names(organism),
                          msg = "peptides dataframe missing from the list organism")
  assertthat::assert_that(is.data.frame(organism$peptides),
                          msg = "peptides is not a dataframe")

  #handle optional fields
  has_pathways <- "pathway" %in% names(organism)
  if(has_pathways) {
    assertthat::assert_that(is.data.frame(organism$pathway),
                            msg = "pathway is not a dataframe")
  }
  has_modules <- "module" %in% names(organism)
  if(has_modules) {
    assertthat::assert_that(is.data.frame(organism$module),
                            msg = "module is not a dataframe")
  }

  #verify that the field organism has the correct columns
  assertthat::assert_that("organism" %in% colnames(organism$organism),
                          msg = "organism column missing from organism")
  assertthat::assert_that("kegg_id" %in% colnames(organism$organism),
                          msg = "kegg_id column missing from organism")
  assertthat::assert_that("letter_code" %in% colnames(organism$organism),
                          msg = "letter_code column missing from organism")
  assertthat::assert_that("genus" %in% colnames(organism$organism),
                          msg = "genus column missing from organism")
  assertthat::assert_that("species" %in% colnames(organism$organism),
                          msg = "species column missing from organism")

  #verify that the field protein has the correct columns
  assertthat::assert_that("protein_id" %in% colnames(organism$protein),
                          msg = "protein_id column missing from protein")
  assertthat::assert_that("name" %in% colnames(organism$protein),
                          msg = "name column missing from protein")
  assertthat::assert_that("definition" %in% colnames(organism$protein),
                          msg = "definition column missing from protein")
  assertthat::assert_that("orthology" %in% colnames(organism$protein),
                          msg = "orthology column missing from protein")
  assertthat::assert_that("position" %in% colnames(organism$protein),
                          msg = "position column missing from protein")
  assertthat::assert_that("motif" %in% colnames(organism$protein),
                          msg = "motif column missing from protein")
  assertthat::assert_that("aaseq" %in% colnames(organism$protein),
                          msg = "aaseq column missing from protein")

  #verify that the field pathway has the correct columns
  if(has_pathways) {
    assertthat::assert_that("protein_id" %in% colnames(organism$pathway),
                            msg = "protein_id column missing from pathway")
    assertthat::assert_that("short_path" %in% colnames(organism$pathway),
                            msg = "short_path column missing from pathway")
    assertthat::assert_that("description" %in% colnames(organism$pathway),
                            msg = "description column missing from pathway")
  }

  #verify that the field module has the correct columns
  if(has_modules) {
    assertthat::assert_that("protein_id" %in% colnames(organism$module),
                            msg = "protein_id column missing from module")
    assertthat::assert_that("module_code" %in% colnames(organism$module),
                            msg = "module_code column missing from module")
    assertthat::assert_that("description" %in% colnames(organism$module),
                            msg = "description column missing from module")
  }

  #verify that the field enzyme has the correct columns
  assertthat::assert_that("protein_id" %in% colnames(organism$enzyme),
                          msg = "protein_id column missing from enzyme")
  assertthat::assert_that("Enzyme" %in% colnames(organism$enzyme),
                          msg = "module_code column missing from enzyme")
  assertthat::assert_that("description" %in% colnames(organism$enzyme),
                          msg = "description column missing from enzyme")

  #verify that the field db_Links has the correct columns
  assertthat::assert_that("protein_id" %in% colnames(organism$db_links),
                          msg = "protein_id column missing from db_links")
  assertthat::assert_that("database" %in% colnames(organism$db_links),
                          msg = "database column missing from db_links")
  assertthat::assert_that("id" %in% colnames(organism$db_links),
                          msg = "id column missing from db_links")

  #verify that the field peptides has the correct columns
  assertthat::assert_that("protein_id" %in% colnames(organism$peptides),
                          msg = "protein_id column missing from peptides")
  assertthat::assert_that("peptide" %in% colnames(organism$peptides),
                          msg = "peptide column missing from peptides")
  assertthat::assert_that("mass" %in% colnames(organism$peptides),
                          msg = "mass column missing from peptides")

  if(in_set == 1) {

    con1 <- DBI::dbConnect(RMariaDB::MariaDB(),
                      dbname = conn$dbname,
                      host = conn$host,
                      port = conn$port,
                      user = conn$user,
                      password = conn$password)

    small_peptides <- organism$peptides[nchar(organism$peptides$peptide)<=max_peptide_length,]

    DBI::dbExecute(con1, "truncate table candidate.upload_peptides")


    DBI::dbWriteTable(
      conn = con1,
      DBI::Id(schema="candidate",table="upload_peptides"),
      value = small_peptides,
      overwrite = F, append = T
    )
    #assign peptide ids for peptides that are already in the database
    DBI::dbExecute(con1, 'update candidate.upload_peptides up
              join candidate.peptides p on p.peptide_original = up.peptide set up.peptide_id = p.id')


    DBI::dbDisconnect(con1)

    stop_time <- Sys.time()
    diff_time <- formatC(as.numeric(stop_time, units = "secs") - as.numeric(start_time, units = "secs"), digits=1, format= "f")

    return(paste0("peptides took ", diff_time, " seconds"))
  }
  #handle all other  uploads
  if(in_set == 2) {

    con2 <- DBI::dbConnect(RMariaDB::MariaDB(),
                      dbname = conn$dbname,
                      host = conn$host,
                      port = conn$port,
                      user = conn$user,
                      password = conn$password)

    large_peptides <- organism$peptides[nchar(organism$peptides$peptide)>max_peptide_length,]

    #print(paste0("Have the max_peptide_length set to ", max_peptide_length, " and small has ",nrow(small_peptides) , " rows, while large has ", nrow(large_peptides) , " rows" ))

    DBI::dbWriteTable(
      conn = con2,
      DBI::Id(schema="candidate",table="upload_filtered_peptides"),
      value = large_peptides,
      field.types = c(protein_id="varchar(4000)",peptide="varchar(20000)",
                      mass="numeric(13,4)"),
      overwrite = T
    )


    DBI::dbExecute(con2, "truncate table candidate.upload_proteins")

    DBI::dbWriteTable(
      conn = con2,
      DBI::Id(schema="candidate",table="upload_proteins"),
      value = organism$protein,
      overwrite = F, append = T
    )

    #assign sequence ids for proteins that already have their sequence in the database
    DBI::dbExecute(con2, 'update candidate.upload_proteins up
              join candidate.sequences s on s.sequence_hash = SHA2(up.aaseq,256) set up.sequence_id = s.id')

    DBI::dbWriteTable(
      conn = con2,
      DBI::Id(schema="candidate",table="upload_organism"),
      value = organism$organism,
      field.types = c(organism="varchar(4000)",kegg_id="varchar(4000)",
                      letter_code="varchar(4000)",genus="varchar(4000)",
                      species="varchar(4000)"),
      overwrite = T
    )

    DBI::dbWriteTable(
      conn = con2,
      DBI::Id(schema="candidate",table="upload_pathways"),
      value = organism$pathway,
      field.types = c(protein_id="varchar(4000)",short_path="varchar(4000)",
                      description="varchar(4000)"),
      overwrite = T
    )


    DBI::dbWriteTable(
      conn = con2,
      DBI::Id(schema="candidate",table="upload_enzymes"),
      value = organism$enzyme,
      field.types = c(protein_id="varchar(4000)",Enzyme="varchar(4000)",
                      description="varchar(4000)"),
      overwrite = T
    )


    DBI::dbWriteTable(
      conn = con2,
      DBI::Id(schema="candidate",table="upload_module"),
      value = organism$module,
      field.types = c(protein_id="varchar(4000)",module_code="varchar(4000)",
                      description="varchar(4000)"),
      overwrite = T
    )

    DBI::dbWriteTable(
      conn = con2,
      DBI::Id(schema="candidate",table="upload_db_links"),
      value = organism$db_links,
      field.types = c(protein_id="varchar(4000)",database="varchar(4000)",
                      id="varchar(4000)"),
      overwrite = T
    )

    DBI::dbDisconnect(con2)

    stop_time <- Sys.time()
    diff_time <- formatC(as.numeric(stop_time, units = "secs") - as.numeric(start_time, units = "secs"), digits=1, format= "f")

    return(paste0("all other tables took ", diff_time, " seconds"))

  }


}

#'Removes all data associated with the organism.  If the organism is partially
#'inserted it may not properly delete the information.  Also if peptide
#'information is partially inserted it will not fully poplate in future loads
#'of the organism.
#'
#'`delete_organism` removes all data associated with the organism
#'
#'@param conn database connection values to create a MySQL connection
#'@param organism_id the database id for the organism
#'
#'@importFrom assertthat assert_that
#'@importFrom DBI sqlInterpolate dbExecute dbDisconnect dbConnect
#'@importFrom RMariaDB MariaDB
#'
#'@author Dustin Crockett
#'
#'@export
delete_organism <- function(conn, organism_id) {
  #validate the conn list
  # verify that the conn is a list
  assertthat::assert_that(is.list(conn),
                          msg = "conn is not a list. Make sure conn is a list.")
  # verify that conn has the correct fields
  assertthat::assert_that("dbname" %in% names(conn),
                          msg = "dbname is missing from the list conn")
  assertthat::assert_that("host" %in% names(conn),
                          msg = "host is missing from the list conn")
  assertthat::assert_that("port" %in% names(conn),
                          msg = "port is missing from the list conn")
  assertthat::assert_that("user" %in% names(conn),
                          msg = "user is missing from the list conn")
  assertthat::assert_that("password" %in% names(conn),
                          msg = "password is missing from the list conn")

  assertthat::assert_that(is.numeric(organism_id),
                          msg = "The provided organism_id is not a valid number.")

  con1 <- DBI::dbConnect(RMariaDB::MariaDB(),
                    dbname = conn$dbname,
                    host = conn$host,
                    port = conn$port,
                    user = conn$user,
                    password = conn$password)

  #delete all protein_to_dblinks for the organism
  sqlcmd <- DBI::sqlInterpolate(con1, "delete from candidate.protein_to_dblinks ptd where protein_id in
                           (select id from candidate.proteins p where organism_id = ?org_id)", org_id = organism_id)
  DBI::dbExecute(con1, sqlcmd)

  #delete all protein_to_pathways for the organism
  sqlcmd <- DBI::sqlInterpolate(con1, "delete from candidate.protein_pathways where protein_id in
                           (select id from candidate.proteins p where organism_id = ?org_id)", org_id = organism_id)
  DBI::dbExecute(con1, sqlcmd)

  #delete all protein_to_enzymes for the organism
  sqlcmd <- DBI::sqlInterpolate(con1, "delete from candidate.enzymes where protein_id in
                           (select id from candidate.proteins p where organism_id = ?org_id)", org_id = organism_id)
  DBI::dbExecute(con1, sqlcmd)

  #delete all protein_to_modules for the organism
  sqlcmd <- DBI::sqlInterpolate(con1, "delete from candidate.protein_modules where protein_id in
                           (select id from candidate.proteins p where organism_id = ?org_id)", org_id = organism_id)
  DBI::dbExecute(con1, sqlcmd)

  #delete all sequence_to_peptides that are only referenced by this organism
  sqlcmd <- DBI::sqlInterpolate(con1, "delete from candidate.sequence_to_peptides where sequence_id in
                            (select s.id from candidate.sequences s
		                                left join candidate.proteins pp on pp.sequence_id = s.id and pp.organism_id <> ?org_id
                                    where s.id in (select p.sequence_id from candidate.proteins p where organism_id = ?org_id)
                                    and pp.id is null)", org_id = organism_id)
  DBI::dbExecute(con1, sqlcmd)

  #delete all sequence_to_peptides_filtered associated with sequences only referenced by this organism
  sqlcmd <- DBI::sqlInterpolate(con1, "delete from candidate.sequence_to_peptides_filtered where sequence_id in
                            (select s.id from candidate.sequences s
		                                left join candidate.proteins pp on pp.sequence_id = s.id and pp.organism_id <> ?org_id
                                    where s.id in (select p.sequence_id from candidate.proteins p where organism_id = ?org_id)
                                    and pp.id is null)", org_id = organism_id)
  DBI::dbExecute(con1, sqlcmd)

  #delete all sequences that are only referenced by this organism
  sqlcmd <- DBI::sqlInterpolate(con1, "delete from candidate.sequence where id in
                            (select s.id from candidate.sequences s
		                                left join candidate.proteins pp on pp.sequence_id = s.id and pp.organism_id <> ?org_id
                                    where s.id in (select p.sequence_id from candidate.proteins p where organism_id = ?org_id)
                                    and pp.id is null)", org_id = organism_id)
  DBI::dbExecute(con1, sqlcmd)



  #delete all proteins for the organism
  sqlcmd <- DBI::sqlInterpolate(con1, "delete from candidate.proteins p where organism_id = ?org_id", org_id = organism_id)
  DBI::dbExecute(con1, sqlcmd)

  #delete all organisms_to_peptides for this organism
  sqlcmd <- DBI::sqlInterpolate(con1, "delete from candidate.organisms_to_peptides where organism_id = ?org_id", org_id = organism_id)
  DBI::dbExecute(con1, sqlcmd)

  #delete the organism
  sqlcmd <- DBI::sqlInterpolate(con1, "delete from candidate.organisms where id = ?org_id", org_id = organism_id)
  DBI::dbExecute(con1, sqlcmd)

  DBI::dbDisconnect(con1)
}

#'Populate the database with a given organism
#'This method is multi-threaded.  First calling upload organism which uses two
#'threads to upload the organism data into the database.  Then this method
#'populate_first_step in two threads and finishes off by calling populate_second_step
#'in three threads.  The first step populates tables needed for the actions in
#'the seconds step.  The second step will not start until both threads in the first
#'step complete.  If this method gives errors verify that mysql server configuration
#'modifications have been made as documented.
#'
#'Throughout the population process information messages are printed out.  At least
#'five lines of information is output (with word wrap most likely 8 lines).
#'
#'`populate_organism` populates the database with the provided organism.
#'
#'
#'@param conn database connection values to create a MySQL connection
#'@param organism A list of data.frames that holds all information for the organism
#'@param max_peptide_length the maximum character length of peptides to be imported
#'
#'@return true when successful
#'@importFrom assertthat assert_that
#'@importFrom DBI dbGetQuery dbConnect dbDisconnect
#'@importFrom RMariaDB MariaDB
#'@importFrom parallel parLapply makeCluster clusterEvalQ clusterExport stopCluster
#'
#'@author Dustin Crockett
#'
#'@export
populate_organism <- function(conn, organism, max_peptide_length=250) {
  start_time = Sys.time()

  #validate the conn list
  # verify that the conn is a list
  assertthat::assert_that(is.list(conn),
                          msg = "conn is not a list. Make sure conn is a list.")
  # verify that conn has the correct fields
  assertthat::assert_that("dbname" %in% names(conn),
                          msg = "dbname is missing from the list conn")
  assertthat::assert_that("host" %in% names(conn),
                          msg = "host is missing from the list conn")
  assertthat::assert_that("port" %in% names(conn),
                          msg = "port is missing from the list conn")
  assertthat::assert_that("user" %in% names(conn),
                          msg = "user is missing from the list conn")
  assertthat::assert_that("password" %in% names(conn),
                          msg = "password is missing from the list conn")

  #upload the organism data into the upload tables in the database
  upload_organism(conn,organism, max_peptide_length)


  # verify that the organism is a list
  assertthat::assert_that(is.list(organism),
                          msg = "organism is not a list. Make sure organism is a list.")

  #handle optional fields
  has_pathways <- "pathway" %in% names(organism)
  has_modules <- "module" %in% names(organism)

  con <- DBI::dbConnect(RMariaDB::MariaDB(),
                   dbname = conn$dbname,
                   host = conn$host,
                   port = conn$port,
                   user = conn$user,
                   password = conn$password)

  #if the organism is already in the database delete it from the database so it can be reloaded
  org_count <- DBI::dbGetQuery(con, "select count(*) organism_count from candidate.organisms o
                          join candidate.upload_organism uo on uo.kegg_id = o.kegg_id")
  if("id" %in% names(org_count)){
    if(is.numeric(org_count$id)) {
      delete_organism(conn,org_count$id)
    }
  }

  DBI::dbDisconnect(con)
  mid_start_time <- Sys.time()
  range_test <-  c(1,2)

  cl <- makeCluster(2)
  ## A bootstrapping example, which can be done in many ways:
  clusterEvalQ(cl, {
    ## set up each worker.
    library(DBI)
    library(RMariaDB)
    NULL
  })
  full_result <- parLapply("cl"=cl, "X" = range_test, "fun" = populate_first_step, chunk.size = 1, conn= conn)

  stopCluster(cl)

  stop_time <- Sys.time()
  diff_time <- formatC(as.numeric(stop_time, units = "secs") - as.numeric(mid_start_time, units = "secs"), digits=1, format= "f")
  cat(paste0("upload of ", full_result[1], " and ", full_result[2], " total time took ", diff_time, " seconds\n"))
  mid_start_time <- Sys.time()

  range_test <-  c(1,2,3)

  cl <- makeCluster(3)
  ## A bootstrapping example, which can be done in many ways:
  clusterEvalQ(cl, {
    ## set up each worker.
    library(DBI)
    library(RMariaDB)
    NULL
  })
  full_result <- parLapply("cl"=cl, "X" = range_test, "fun" = populate_second_step, chunk.size = 1, conn= conn, has_pathways=has_pathways, has_modules=has_modules)

  stopCluster(cl)

  stop_time <- Sys.time()
  diff_time <- formatC(as.numeric(stop_time, units = "secs") - as.numeric(mid_start_time, units = "secs"), digits=1, format= "f")
  cat(paste0("population of ", full_result[1], ", ", full_result[2], " and ", full_result[3], " total time took ", diff_time, " seconds\n"))

  stop_time <- Sys.time()
  diff_time <- formatC(as.numeric(stop_time, units = "secs") - as.numeric(start_time, units = "secs"), digits=1, format= "f")
  cat(paste0("Started at ", start_time, ", and finished at ", stop_time, ", took a total duration of ", diff_time, " seconds\n"))
}

#'A helper method that allows for multi-threading of organism populating
#'This is an internal method used by populate_organism and requires
#'the conn list of connection information to be passed into it by way of
#'cluster import.  This method can be called two different times with a
#'1 or a 2 as the in_set value to populate base tables needed for the next
#'step.
#'
#'@param in_set a number that defines which step of logic to use
#'@param conn database connection values to create a MySQL connection
#'
#'@return string describing how long in seconds that it took for the part to complete including how many rows were inserted
#'@importFrom assertthat assert_that
#'@importFrom DBI dbExecute dbDisconnect dbConnect
#'@importFrom RMariaDB MariaDB
#'
#'@author Dustin Crockett
populate_first_step <- function(in_set, conn) {
  mid_start_time <- Sys.time()

  #validate the conn list
  # verify that the conn is a list
  assertthat::assert_that(is.list(conn),
                          msg = "conn is not a list. Make sure conn is a list.")
  # verify that conn has the correct fields
  assertthat::assert_that("dbname" %in% names(conn),
                          msg = "dbname is missing from the list conn")
  assertthat::assert_that("host" %in% names(conn),
                          msg = "host is missing from the list conn")
  assertthat::assert_that("port" %in% names(conn),
                          msg = "port is missing from the list conn")
  assertthat::assert_that("user" %in% names(conn),
                          msg = "user is missing from the list conn")
  assertthat::assert_that("password" %in% names(conn),
                          msg = "password is missing from the list conn")

  #populate organism tables, sequences table and peptide table
  if(in_set == 1) {
    con1 <- DBI::dbConnect(RMariaDB::MariaDB(),
                      dbname = conn$dbname,
                      host = conn$host,
                      port = conn$port,
                      user = conn$user,
                      password = conn$password)


    genus_count <- DBI::dbExecute(con1, 'insert ignore into candidate.genus(name)
                             select distinct genus
                             from candidate.upload_organism')

    mid_stop_time <- Sys.time()
    genus_time <- formatC(as.numeric(mid_stop_time, units = "secs") - as.numeric(mid_start_time, units = "secs"), digits=3, format= "f")
    mid_start_time <- mid_stop_time

    species_count <- DBI::dbExecute(con1, 'insert ignore into candidate.species(name, genus_id)
                               select distinct uo.species, g.id
                               from candidate.upload_organism uo, candidate.genus g
                               where g.name = uo.genus')

    mid_stop_time <- Sys.time()
    species_time <- formatC(as.numeric(mid_stop_time, units = "secs") - as.numeric(mid_start_time, units = "secs"), digits=3, format= "f")
    mid_start_time <- mid_stop_time

    organisms_count <- DBI::dbExecute(con1, 'insert ignore into candidate.organisms(kegg_id, name, kegg_org_code, species_id, peptide_count, protein_count)
                                              select distinct uo.kegg_id, uo.organism, uo.letter_code, s.id, peptides.peptide_count, proteins.protein_count
                                              from candidate.upload_organism uo
                                              join candidate.genus g on g.name = uo.genus
                                              join candidate.species s on  g.id = s.genus_id and s.name = uo.species
                                              join (select count(distinct up.peptide) peptide_count from candidate.upload_peptides up) peptides
                                              join (select count(*) protein_count from (select distinct protein_id, aaseq from candidate.upload_proteins upr) prots ) proteins')

    mid_stop_time <- Sys.time()
    organisms_time <- formatC(as.numeric(mid_stop_time, units = "secs") - as.numeric(mid_start_time, units = "secs"), digits=3, format= "f")
    mid_start_time <- mid_stop_time

    peptides_count <- DBI::dbExecute(con1, "insert into candidate.peptides(peptide_original, mass, `length`, peptide_substitution)
                                select distinct p.peptide, p.mass, length(p.peptide), replace(p.peptide,'I','L')
                                from candidate.upload_peptides p
                                where p.peptide_id is null " )

    mid_stop_time <- Sys.time()
    peptides_time <- formatC(as.numeric(mid_stop_time, units = "secs") - as.numeric(mid_start_time, units = "secs"), digits=3, format= "f")
    mid_start_time <- mid_stop_time

    sequences_count <- DBI::dbExecute(con1, 'insert into candidate.sequences(sequence_hash,sequence, `length`)
                                 select distinct SHA2(up.aaseq,256), up.aaseq, length(up.aaseq)
                                 from candidate.upload_proteins up
                                 where up.sequence_id is null')

    mid_stop_time <- Sys.time()
    sequences_time <- formatC(as.numeric(mid_stop_time, units = "secs") - as.numeric(mid_start_time, units = "secs"), digits=3, format= "f")


    DBI::dbDisconnect(con1)
    return(paste0("Genus(", genus_count, ") in ", genus_time, "s"
                  ,", Species(", species_count, ") in ", species_time, "s"
                  ,", Organisms(", organisms_count, ") in ", organisms_time, "s"
                  ,", Peptides(", peptides_count, ") in ", peptides_time, "s"
                  ,", Sequences(", sequences_count, ") in ", sequences_time, "s"))
  }

  #populate peptide_tags table
  if(in_set == 2) {
    con2 <- DBI::dbConnect(RMariaDB::MariaDB(),
                      dbname = conn$dbname,
                      host = conn$host,
                      port = conn$port,
                      user = conn$user,
                      password = conn$password)

    peptide_tags_count <- DBI::dbExecute(con2, "insert into candidate.peptide_tags(peptide_tag)
                                    with recursive cte_peps as (
                                    select peptide, substring(peptide, 1, 5) peptide_tag
                                    from (select distinct replace(peptide,'I','L') peptide  from candidate.upload_peptides where peptide_id is null) p
                                    union all
                                    select substring(peptide, 2) peptide, substring(peptide, 2, 5) peptide_tag
                                    from cte_peps
                                    where length(peptide) > 5 )
                                    select distinct peptide_tag
                                    from cte_peps
                                    where peptide_tag not in (select peptide_tag from candidate.peptide_tags pt)")

    mid_stop_time <- Sys.time()
    peptide_tags_time <- formatC(as.numeric(mid_stop_time, units = "secs") - as.numeric(mid_start_time, units = "secs"), digits=3, format= "f")

    DBI::dbDisconnect(con2)
    return(paste0("Peptide_tags(", peptide_tags_count, ") in ", peptide_tags_time, "s"))
  }

}

#'A helper method that allows for multi-threading of organism populating
#'This is an internal method used by populate_organism and requires
#'the has_pathways boolean variable, the has_modules boolean variable and,
#'the conn list of connection information to be passed into it by way of
#'cluster import.  This method can be called two different times with a
#'1 or a 2 as the in_set value to populate base tables needed for the next
#'step.
#'
#'@param in_set a number that defines which step of logic to use
#'@param conn database connection values to create a MySQL connection
#'@param has_pathways When T process the protein pathways that are already uploaded
#'@param has_modules When T process the protein modules that are already uploaded
#'
#'@return string describing how long in seconds that it took for the part to complete including how many rows were inserted
#'@importFrom DBI dbExecute dbDisconnect dbConnect
#'@importFrom RMariaDB MariaDB
#'
#'@author Dustin Crockett
populate_second_step <- function(in_set, conn, has_pathways=F, has_modules=F) {
  mid_start_time <- Sys.time()

  #validate the conn list
  # verify that the conn is a list
  assertthat::assert_that(is.list(conn),
                          msg = "conn is not a list. Make sure conn is a list.")
  # verify that conn has the correct fields
  assertthat::assert_that("dbname" %in% names(conn),
                          msg = "dbname is missing from the list conn")
  assertthat::assert_that("host" %in% names(conn),
                          msg = "host is missing from the list conn")
  assertthat::assert_that("port" %in% names(conn),
                          msg = "port is missing from the list conn")
  assertthat::assert_that("user" %in% names(conn),
                          msg = "user is missing from the list conn")
  assertthat::assert_that("password" %in% names(conn),
                          msg = "password is missing from the list conn")

  #populate peptide_map table
  if(in_set == 1) {
    con1 <- DBI::dbConnect(RMariaDB::MariaDB(),
                      dbname = conn$dbname,
                      host = conn$host,
                      port = conn$port,
                      user = conn$user,
                      password = conn$password)

    peptide_map_count <- DBI::dbExecute(con1, "insert into candidate.peptide_map(peptide_tag_id, peptide_id, first_location, max_characters_left, count_in_peptide, mass)
                                   with recursive cte_peps as (
                                   select peptide_full, peptide, substring(peptide, 1, 5) peptide_tag, length(peptide)-5 extra_length, 1 `position`
                                   from (select distinct peptide peptide_full, replace(peptide,'I','L') peptide from candidate.upload_peptides where peptide_id is null) p
                                   union all
                                   select peptide_full, substring(peptide, 2) peptide, substring(peptide, 2, 5) peptide_tag, length(peptide)-6 extra_length, position + 1 `position`
                                   from cte_peps
                                   where length(peptide) > 5 )
                                   select distinct ps.id, pep.id, min(cp.position) `position`, max(cp.extra_length) extra_length, count(cp.peptide_full) count_in_peptide, max(pep.mass) mass
                                   from cte_peps cp, candidate.peptides pep, candidate.peptide_tags ps
                                   where ps.peptide_tag = cp.peptide_tag and pep.peptide_original = cp.peptide_full
                                   group by ps.id, pep.id")

    mid_stop_time <- Sys.time()
    peptide_map_time <- formatC(as.numeric(mid_stop_time, units = "secs") - as.numeric(mid_start_time, units = "secs"), digits=3, format= "f")

    DBI::dbDisconnect(con1)
    return(paste0("peptide_map(", peptide_map_count, ") in ", peptide_map_time, "s"))
  }
  #populate organisms_to_peptides table
  if(in_set == 2) {
    con2 <- DBI::dbConnect(RMariaDB::MariaDB(),
                      dbname = conn$dbname,
                      host = conn$host,
                      port = conn$port,
                      user = conn$user,
                      password = conn$password)

    organisms_to_peptides_count <- DBI::dbExecute(con2, 'insert into candidate.organisms_to_peptides(organism_id, peptide_id, total_count)
                                            select o.id, p.id, count(p.peptide_substitution ) total_count
                                             from candidate.upload_peptides up
                                             join candidate.peptides p on up.peptide = p.peptide_original
                                             join candidate.organisms o on o.kegg_id in (select kegg_id from candidate.upload_organism)
                                            group by o.id, p.id')

    mid_stop_time <- Sys.time()
    organisms_to_peptides_time <- formatC(as.numeric(mid_stop_time, units = "secs") - as.numeric(mid_start_time, units = "secs"), digits=3, format= "f")

    DBI::dbDisconnect(con2)
    return(paste0("organisms_to_peptides(", organisms_to_peptides_count, ") in ", organisms_to_peptides_time, "s"))
  }
  #populate all remaining tables
  if(in_set == 3) {
    con3 <- DBI::dbConnect(RMariaDB::MariaDB(),
                      dbname = conn$dbname,
                      host = conn$host,
                      port = conn$port,
                      user = conn$user,
                      password = conn$password)

    dblinks_count <- DBI::dbExecute(con3, 'insert ignore into candidate.dblinks(`database`)
                               select distinct `database`
                               from candidate.upload_db_links')

    mid_stop_time <- Sys.time()
    dblinks_time <- formatC(as.numeric(mid_stop_time, units = "secs") - as.numeric(mid_start_time, units = "secs"), digits=3, format= "f")
    mid_start_time <- mid_stop_time

    proteins_count <- DBI::dbExecute(con3, 'insert into candidate.proteins(protein_kegg_id, `name`, definition, orthology, position, motif, sequence_id, organism_id, sequence_count_in_org)
                                select up.protein_id, up.name, up.definition, up.orthology, up.position, up.motif, s.id, o.id, pro_count.pCount
                                from candidate.upload_proteins up
                                join candidate.sequences s on SHA2(up.aaseq,256) = s.sequence_hash
                                join candidate.upload_organism uo
                                join candidate.organisms o on uo.kegg_id = o.kegg_id
                                join (select aaseq, count(up.protein_id) pCount from candidate.upload_proteins up group by aaseq) pro_count on pro_count.aaseq = up.aaseq')

    mid_stop_time <- Sys.time()
    proteins_time <- formatC(as.numeric(mid_stop_time, units = "secs") - as.numeric(mid_start_time, units = "secs"), digits=3, format= "f")
    mid_start_time <- mid_stop_time

    enzyme_count <- DBI::dbExecute(con3, 'insert into candidate.enzymes(protein_id, `key`, description)
                              select p.id, ue.Enzyme, ue.description
                              from candidate.upload_enzymes ue
                              join candidate.organisms o on o.kegg_id in (select kegg_id from candidate.upload_organism)
                              join candidate.proteins p on ue.protein_id = p.protein_kegg_id and organism_id = o.id
                              join candidate.upload_proteins up on ue.protein_id = up.protein_id
                              join candidate.sequences s on SHA2(up.aaseq,256) = s.sequence_hash and s.id = p.sequence_id
                              ')

    mid_stop_time <- Sys.time()
    enzyme_time <- formatC(as.numeric(mid_stop_time, units = "secs") - as.numeric(mid_start_time, units = "secs"), digits=3, format= "f")
    mid_start_time <- mid_stop_time

    protein_to_dblinks_count <- DBI::dbExecute(con3, 'insert into candidate.protein_to_dblinks(protein_id, dblink_id, `key`)
                                          select distinct p.id, dbl.id, ud.id
                                          from candidate.upload_db_links ud
                                          join candidate.organisms o on o.kegg_id in (select kegg_id from candidate.upload_organism)
                                          join candidate.proteins p on ud.protein_id = p.protein_kegg_id and p.organism_id = o.id
                                          join candidate.dblinks dbl on dbl.database = ud.database
                                          join candidate.upload_proteins up on ud.protein_id = up.protein_id
                                          join candidate.sequences s on SHA2(up.aaseq,256) = s.sequence_hash and s.id = p.sequence_id')

    mid_stop_time <- Sys.time()
    protein_to_dblinks_time <- formatC(as.numeric(mid_stop_time, units = "secs") - as.numeric(mid_start_time, units = "secs"), digits=3, format= "f")
    mid_start_time <- mid_stop_time

    if(has_pathways){
      protein_pathways_count <- DBI::dbExecute(con3, 'insert into candidate.protein_pathways(protein_id, short_path, description)
                                          select p.id, up.short_path, up.description
                                          from candidate.upload_pathways up
                                          join candidate.organisms o on o.kegg_id in (select kegg_id from candidate.upload_organism)
                                          join candidate.proteins p on up.protein_id = p.protein_kegg_id and p.organism_id = o.id
                                          join candidate.upload_proteins upp on upp.protein_id = up.protein_id
                                          join candidate.sequences s on SHA2(upp.aaseq,256) = s.sequence_hash and s.id = p.sequence_id
                                          where up.short_path is not null')
    } else {
      protein_pathways_count <- 0
    }

    mid_stop_time <- Sys.time()
    protein_pathways_time <- formatC(as.numeric(mid_stop_time, units = "secs") - as.numeric(mid_start_time, units = "secs"), digits=3, format= "f")
    mid_start_time <- mid_stop_time

    if(has_modules){
      protein_modules_count <- DBI::dbExecute(con3, 'insert into candidate.protein_modules(protein_id, module_core, description)
                                         select p.id, um.module_code , um.description
                                         from candidate.upload_module um
                                         join candidate.organisms o on o.kegg_id in (select kegg_id from candidate.upload_organism)
                                         join candidate.proteins p on um.protein_id = p.protein_kegg_id and p.organism_id = o.id
                                         join candidate.upload_proteins up on um.protein_id = up.protein_id
                                         join candidate.sequences s on SHA2(up.aaseq,256) = s.sequence_hash and s.id = p.sequence_id
                                         where um.module_code is not null')
    } else {
      protein_modules_count <- 0
    }

    mid_stop_time <- Sys.time()
    protein_modules_time <- formatC(as.numeric(mid_stop_time, units = "secs") - as.numeric(mid_start_time, units = "secs"), digits=3, format= "f")
    mid_start_time <- mid_stop_time

    peptides_filtered_count <- DBI::dbExecute(con3, 'insert ignore into candidate.peptides_filtered(peptide_hash, peptide,mass,`length`)
                                         select distinct SHA2(p.peptide,256), p.peptide, p.mass, length(p.peptide)
                                         from candidate.upload_filtered_peptides p' )

    mid_stop_time <- Sys.time()
    peptides_filtered_time <- formatC(as.numeric(mid_stop_time, units = "secs") - as.numeric(mid_start_time, units = "secs"), digits=3, format= "f")
    mid_start_time <- mid_stop_time


    sequence_to_peptides_count <- DBI::dbExecute(con3, 'insert ignore into candidate.sequence_to_peptides(sequence_id,	peptide_id, total_count)
                                          select p.sequence_id, pep.id, dups.dup_count
                                            from candidate.upload_peptides up
                                            join candidate.peptides pep on up.peptide = pep.peptide_original
                                            join candidate.organisms o on o.kegg_id in (select kegg_id from candidate.upload_organism)
                                            join candidate.proteins p on up.protein_id = p.protein_kegg_id and p.organism_id = o.id
                                            join candidate.upload_proteins upp on upp.protein_id = up.protein_id and upp.sequence_id is null
                                            join candidate.sequences s on SHA2(upp.aaseq,256) = s.sequence_hash and s.id = p.sequence_id
                                            join (select aaseq, peptide, max(mass_count) dup_count
                    												 from (select up.aaseq, upe.peptide, upe.protein_id, count(upe.mass) mass_count from candidate.upload_proteins up
                    															join candidate.upload_peptides upe on upe.protein_id = up.protein_id
                    														group by up.aaseq, upe.peptide, upe.protein_id ) dups
                    													group by aaseq, peptide) dups on dups.aaseq = upp.aaseq and dups.peptide = pep.peptide_original
                                            group by p.sequence_id, pep.id')

    mid_stop_time <- Sys.time()
    sequence_to_peptides_time <- formatC(as.numeric(mid_stop_time, units = "secs") - as.numeric(mid_start_time, units = "secs"), digits=3, format= "f")
    mid_start_time <- mid_stop_time

    sequence_to_peptides_filtered_count <- DBI::dbExecute(con3, 'insert ignore into candidate.sequence_to_peptides_filtered(sequence_id,	peptides_filtered_id)
                                                     select distinct p.sequence_id, pep.id
                                                     from candidate.upload_filtered_peptides up
                                                     join candidate.peptides_filtered pep on up.peptide = pep.peptide
                                                     join candidate.organisms o on o.kegg_id in (select kegg_id from candidate.upload_organism)
                                                     join candidate.proteins p on up.protein_id = p.protein_kegg_id and p.organism_id = o.id
                                                     join candidate.upload_proteins upp on upp.protein_id = up.protein_id
                                                     join candidate.sequences s on SHA2(upp.aaseq,256) = s.sequence_hash and s.id = p.sequence_id ')

    mid_stop_time <- Sys.time()
    sequence_to_peptides_filtered_time <- formatC(as.numeric(mid_stop_time, units = "secs") - as.numeric(mid_start_time, units = "secs"), digits=3, format= "f")

    DBI::dbDisconnect(con3)
    return(paste0("dblinks(", dblinks_count, ") in ", dblinks_time, "s"
                  ,", proteins(", proteins_count, ") in ", proteins_time, "s"
                  ,", enzyme(", enzyme_count, ") in ", enzyme_time, "s"
                  ,", protein_to_dblinks(", protein_to_dblinks_count, ") in ", protein_to_dblinks_time, "s"
                  ,", protein_pathways(", protein_pathways_count, ") in ", protein_pathways_time, "s"
                  ,", protein_modules(", protein_modules_count, ") in ", protein_modules_time, "s"
                  ,", peptides_filtered(", peptides_filtered_count, ") in ", peptides_filtered_time, "s"
                  ,", sequence_to_peptides(", sequence_to_peptides_count, ") in ", sequence_to_peptides_time, "s"
                  ,", sequence_to_peptides_filtered(", sequence_to_peptides_filtered_count, ") in ", sequence_to_peptides_filtered_time, "s"))
  }
}

#'A helper method that allows for multi-threading of calculating of strong peptide counts
#'This is an internal method used by process_strong and requires
#'the conn list of connection information to be passed into it by way of
#'cluster import.  This method will loop through all genus_id values in in_set
#'and populate a temporary table that stores the percentage of organisms in the
#'genus that reference a given peptide, for all peptides referenced by the genus.
#'
#'@param in_set a vector of genus_id values from the database
#'@param conn database connection values to create a MySQL connection
#'
#'@return the in_set vector that was passed into the method
#'
#'@importFrom DBI sqlInterpolate dbExecute dbDisconnect dbConnect
#'@importFrom RMariaDB MariaDB
#'
#'@author Dustin Crockett
analyze_strong_counts <- function(in_set, conn) {

  #validate the conn list
  # verify that the conn is a list
  assertthat::assert_that(is.list(conn),
                          msg = "conn is not a list. Make sure conn is a list.")
  # verify that conn has the correct fields
  assertthat::assert_that("dbname" %in% names(conn),
                          msg = "dbname is missing from the list conn")
  assertthat::assert_that("host" %in% names(conn),
                          msg = "host is missing from the list conn")
  assertthat::assert_that("port" %in% names(conn),
                          msg = "port is missing from the list conn")
  assertthat::assert_that("user" %in% names(conn),
                          msg = "user is missing from the list conn")
  assertthat::assert_that("password" %in% names(conn),
                          msg = "password is missing from the list conn")

  con1 <- DBI::dbConnect(RMariaDB::MariaDB(),
                    dbname = conn$dbname,
                    host = conn$host,
                    port = conn$port,
                    user = conn$user,
                    password = conn$password)
  for(i in in_set) {
    sqlcmd <- DBI::sqlInterpolate(con1, "insert into candidate.strong_peptide_temp(peptide_id, genus_id, strong_percent)
                             select otp.peptide_id, s.genus_id, count(distinct o.id) / genus_count.org_count organism_percentage
                             from candidate.organisms o
                             join candidate.species s on s.id = o.species_id and s.genus_id = ?genus_id
                             join candidate.organisms_to_peptides otp on o.id = otp.organism_id
                             join (select count(distinct o.id) org_count, s.genus_id from candidate.organisms o join candidate.species s on s.id = o.species_id
                             where s.genus_id = ?genus_id
                             group by s.genus_id) genus_count
                             on s.genus_id = genus_count.genus_id
                             group by otp.peptide_id, s.genus_id, genus_count.org_count", genus_id = i)
    DBI::dbExecute(con1, sqlcmd)
  }
  DBI::dbDisconnect(con1)
  return(in_set)
}

#'Populate the database with strong peptides values
#'This method is multi threaded.  First creating a temporary table and then calling analyze_strong_counts
#'in parallel.  The number times analyze_strong_counts is called defined by the core_count variable,
#' the default value is 4.  Once analyze_strong_counts populates the
#'temporary table with the coverage of organisms by peptide and genus.  Next this temporary table
#'is agregated to create strong peptides records for all coverages that stand out from other coverages
#'by the tolerance provided in the tolerance variable, the
#'default value is .053.  Once that is done the temporary table is deleted.
#'
#'Throughout the population process information messages are printed out to show progress.
#'
#'`process_strong` calculates which peptides that are strong for a genus, for all peptides.
#'
#'
#'@param conn database connection values to create a MySQL connection
#'@param core_count This is to total number cores to be used during parallel processing
#'      it should be no greater than 1/2 of total cores
#'@param split_size This is size of list that should be passed to each execution of
#'      analyze_strong_count.
#'@param tolerance the percentage difference between organism coverages within a genus
#'      of the two highest covered genus, for the highest covered genus to be
#'      have a strong peptide
#'
#'@importFrom assertthat assert_that
#'@importFrom DBI sqlInterpolate dbExecute dbConnect dbDisconnect
#'@importFrom RMariaDB MariaDB
#'@importFrom parallel parLapply makeCluster clusterEvalQ clusterExport stopCluster
#'
#'@author Dustin Crockett
#'
#'@export
process_strong <- function(conn, core_count = 2, split_size=10, tolerance=0.053) {
  start_time <- Sys.time()


  #validate the conn list
  # verify that the conn is a list
  assertthat::assert_that(is.list(conn),
                          msg = "conn is not a list. Make sure conn is a list.")
  # verify that conn has the correct fields
  assertthat::assert_that("dbname" %in% names(conn),
                          msg = "dbname is missing from the list conn")
  assertthat::assert_that("host" %in% names(conn),
                          msg = "host is missing from the list conn")
  assertthat::assert_that("port" %in% names(conn),
                          msg = "port is missing from the list conn")
  assertthat::assert_that("user" %in% names(conn),
                          msg = "user is missing from the list conn")
  assertthat::assert_that("password" %in% names(conn),
                          msg = "password is missing from the list conn")

  con1 <- DBI::dbConnect(RMariaDB::MariaDB(),
                    dbname = conn$dbname,
                    host = conn$host,
                    port = conn$port,
                    user = conn$user,
                    password = conn$password)

  #calculate strong peptide
  results <- DBI::dbGetQuery(con1, "select id from candidate.genus")

  id_list <- split(results$id, rep(1:ceiling(length(results$id)/split_size), each=split_size)[1:length(results$id)])

  DBI::dbExecute(con1,'drop table if exists candidate.strong_peptide_temp')

  DBI::dbExecute(con1, 'create table candidate.strong_peptide_temp ( peptide_id int,
            genus_id int2,
            strong_percent float(23),
            primary key (peptide_id, genus_id) )')

  cl <- makeCluster(core_count)

  clusterEvalQ(cl, {
    ## set up each worker.  Could also use clusterExport()
    library(DBI)
    library(RMariaDB)
    NULL
  })
  #print(paste0("range ", range_test))
  full_result <- parLapply("cl"=cl, "X" = id_list, "fun" = analyze_strong_counts, chunk.size = 1, conn= conn)

  end_time = Sys.time()
  diff_time <- format(as.numeric(end_time, units = "secs") - as.numeric(start_time, units = "secs"))
  cat(paste0("Populated strong_peptide_temp for all genus, started at ", start_time, ", and finished at ", end_time, ", took a total duration of ", diff_time, " seconds\n"))
  start_time = end_time

  stopCluster(cl)

  sqlcmd <- DBI::sqlInterpolate(con1,"insert into candidate.strong_peptides(peptide_id, strong_percent, strong_genus_id, second_percent, second_genus_id)
                           select id peptide_id, top_percent, top_genus_id, second_percent, second_genus_id  from
                           (select id, top_percent.strong_percent top_percent, top_percent.genus_id top_genus_id, second_percent.strong_percent second_percent, second_percent.genus_id second_genus_id
                           from candidate.peptides p
                           join candidate.strong_peptide_temp top_percent
                           on p.id = top_percent.peptide_id and top_percent.genus_id = (select genus_id from candidate.strong_peptide_temp where p.id = peptide_id order by strong_percent desc limit 1)
                           left join candidate.strong_peptide_temp second_percent
                           on p.id = second_percent.peptide_id and second_percent.genus_id = (select genus_id from candidate.strong_peptide_temp where p.id = peptide_id order by strong_percent desc limit 1,1)
                           ) results  where results.top_percent >= ifnull(results.second_percent,0) / ?tolerance or results.second_percent is null", tolerance = tolerance)
  DBI::dbExecute(con1, sqlcmd)


  end_time = Sys.time()
  diff_time <- format(as.numeric(end_time, units = "secs") - as.numeric(start_time, units = "secs"))
  cat(paste0("Populated strong_peptides for all genus, started at ", start_time, ", and finished at ", end_time, ", took a total duration of ", diff_time, " seconds\n"))
  start_time = end_time

  #now we update the organisms table with the new strong_peptide_counts

  DBI::dbExecute(con1, "update candidate.organisms oo
	join (select o.id, count(distinct sp.peptide_id ) strong_pep_count
	from candidate.organisms o
		join candidate.species s on o.species_id = s.id
		join candidate.strong_peptides sp on sp.strong_genus_id = s.genus_id
		join candidate.organisms_to_peptides otp on otp.organism_id = o.id and otp.peptide_id = sp.peptide_id
	group by o.id) strong_counts on strong_counts.id = oo.id
	set oo.strong_peptide_count = strong_counts.strong_pep_count")

  #finally we drop the temp table
  #now that we no longer need the strong peptide temporary table we remove it
  DBI::dbExecute(con1, 'drop table candidate.strong_peptide_temp')

  DBI::dbDisconnect(con1)

  end_time = Sys.time()
  diff_time <- format(as.numeric(end_time, units = "secs") - as.numeric(start_time, units = "secs"))
  cat(paste0("Populated strong_peptide_counts for all organisms, started at ", start_time, ", and finished at ", end_time, ", took a total duration of ", diff_time, " seconds\n"))

}

#'A helper method that allows for multi-threading of calculating of overlap coefficients
#'This is an internal method used by process_overlap and requires
#'the conn list of connection information to be passed into it by way of
#'cluster import.  This method will loop through all organisms_id values in in_set
#'and populate a temporary table that stores the percentage of peptide overlap between
#'two organisms in the.  Before exiting this method all calculated values are then
#'copied to the overlap_coefficient table.  If a file_output string is passed using the
#'cluster import the process information is appended to the end of the file otherwise
#'the process information is the return value for the method.
#'
#'@param in_set a vector of organism_id values from the database
#'@param conn database connection values to create a MySQL connection
#'@param file_output the name of the file to output all messages to, if not provided
#'      the return value will be the debug output
#'
#'@return T if a file_output was privided or process information messages if not provided
#'
#'@importFrom DBI sqlInterpolate dbExecute dbDisconnect dbConnect
#'@importFrom RMariaDB MariaDB
#'
#'@author Dustin Crockett
analyze_overlap <- function(in_set, conn, file_output="") {
  start_time <- Sys.time()


  #validate the conn list
  # verify that the conn is a list
  assertthat::assert_that(is.list(conn),
                          msg = "conn is not a list. Make sure conn is a list.")
  # verify that conn has the correct fields
  assertthat::assert_that("dbname" %in% names(conn),
                          msg = "dbname is missing from the list conn")
  assertthat::assert_that("host" %in% names(conn),
                          msg = "host is missing from the list conn")
  assertthat::assert_that("port" %in% names(conn),
                          msg = "port is missing from the list conn")
  assertthat::assert_that("user" %in% names(conn),
                          msg = "user is missing from the list conn")
  assertthat::assert_that("password" %in% names(conn),
                          msg = "password is missing from the list conn")

  return_value <- ""
  con1 <- DBI::dbConnect(RMariaDB::MariaDB(),
                    dbname = conn$dbname,
                    host = conn$host,
                    port = conn$port,
                    user = conn$user,
                    password = conn$password)

  DBI::dbExecute(con1,'drop table if exists candidate.overlap_coefficient_temp, candidate.overlap_coefficient_strong_temp')

  DBI::dbExecute(con1, 'create temporary table candidate.overlap_coefficient_temp ( organism_id_i int2 unsigned,
            organism_id_j int2 unsigned,
            coefficient float(23) not null,
            match_count int3 unsigned not null,
            jaccard_index float(23) not null,
            primary key (organism_id_i, organism_id_j)) ENGINE=MEMORY')

  DBI::dbExecute(con1, 'create temporary table candidate.overlap_coefficient_strong_temp ( organism_id_i int2 unsigned,
            organism_id_j int2 unsigned,
            coefficient float(23) not null,
            match_count int3 unsigned not null,
            jaccard_index float(23) not null,
            primary key (organism_id_i, organism_id_j)) ENGINE=MEMORY')

  for(i in in_set) {
    mid_time <- Sys.time()

    sqlcmd <- DBI::sqlInterpolate(con1, "insert into candidate.overlap_coefficient_temp(organism_id_i, organism_id_j, coefficient, match_count, jaccard_index)
    select  o_i.id organism_id_i, o_j.id organism_id_j
                             , case when o_i.peptide_count > o_j.peptide_count then count(distinct p.id) / o_j.peptide_count
                                  else count(distinct p.id) / o_i.peptide_count end coefficient, count(distinct p.id) match_count,
                                  count(distinct p.id) / (o_i.peptide_count + o_j.peptide_count) jaccard_index
                                  from candidate.organisms o_i
                                  join candidate.organisms_to_peptides otp_i on o_i.id = otp_i.organism_id
                                  join candidate.organisms_to_peptides otp_j on otp_j.peptide_id = otp_i.peptide_id
                                  join candidate.organisms o_j on o_j.id <> o_i.id and o_j.id = otp_j.organism_id
                                  join candidate.peptides p on otp_i.peptide_id = p.id
                                  where o_i.id = ?org_id
                                  group by otp_j.organism_id", org_id = i)

    DBI::dbExecute(con1, sqlcmd)

    sqlcmd <- DBI::sqlInterpolate(con1, "insert into candidate.overlap_coefficient_strong_temp(organism_id_i, organism_id_j, coefficient, match_count, jaccard_index)
    select o_i.id organism_id_i, o_j.id organism_id_j, case when o_i.strong_peptide_count > o_j.strong_peptide_count then coalesce(count(peps.p_id),0) / o_j.strong_peptide_count
              else coalesce(count(peps.p_id),0) / o_i.strong_peptide_count end coefficient, coalesce(count(peps.p_id),0) match_count,
              coalesce(count(peps.p_id),0) / (o_i.strong_peptide_count + o_j.strong_peptide_count) jaccard_index
		from candidate.organisms o_i
			join candidate.organisms o_j on o_i.id <> o_j.id
			left join (select o_i.id o_id_i, o_j.id o_id_j, p.id p_id
				from candidate.organisms o_i
	              join candidate.species s_i on s_i.id = o_i.species_id
	              join candidate.organisms_to_peptides otp_i on o_i.id = otp_i.organism_id
	              join candidate.organisms_to_peptides otp_j on otp_j.peptide_id = otp_i.peptide_id
	              join candidate.organisms o_j on o_j.id <> o_i.id and o_j.id = otp_j.organism_id
	              join candidate.species s_j on o_j.species_id = s_j.id  and s_j.genus_id = s_i.genus_id
	              join candidate.peptides p on otp_i.peptide_id = p.id
	              join candidate.strong_peptides sp_i on sp_i.strong_genus_id = s_i.genus_id and sp_i.peptide_id = otp_i.peptide_id
	              where o_i.id = ?org_id) peps on peps.o_id_i = o_i.id and peps.o_id_j = o_j.id
			where o_i.id = ?org_id
			group by o_j.id", org_id = i)

    DBI::dbExecute(con1, sqlcmd)

    end_time <- Sys.time()
    diff_time <- formatC(as.numeric(end_time, units = "secs") - as.numeric(mid_time, units = "secs"), digits=3, format= "f")
    return_value <- paste0(return_value, "id=", i, " took ", diff_time, " s, ")
    mid_time <- end_time
  }

  DBI::dbExecute(con1, "insert ignore into candidate.overlap_coefficient(organism_id_i, organism_id_j, coefficient, jaccard_index, match_count, strong_coefficient, strong_jaccard_index, strong_match_count)
            select  oc.organism_id_i, oc.organism_id_j, oc.coefficient, oc.jaccard_index, oc.match_count, ocs.coefficient, ocs.jaccard_index, ocs.match_count
            from candidate.overlap_coefficient_temp oc
              join candidate.overlap_coefficient_strong_temp ocs on oc.organism_id_i = ocs.organism_id_i and oc.organism_id_j = ocs.organism_id_j")

  DBI::dbDisconnect(con1)
  end_time <- Sys.time()
  diff_time <- formatC(as.numeric(end_time, units = "secs") - as.numeric(start_time, units = "secs"), digits=3, format= "f")
  return_value <- paste0("Populated ", length(in_set), " overlaps, started at ", start_time, " finished at ", end_time, ", took ", diff_time, " seconds \n", return_value,"\n")
  if(file_output != "")
  {
    write(return_value,file=file_output,append=TRUE)
    return_value <- T
  }

  return(return_value)
}

#'Populate the database with overlap coefficient of peptides between all organisms
#'This method is multi threaded.  Each call analyze_overlap creates its own temperary table to load values
#'into, once all overlap coefficients are calculated for that call the value are copied to the
#'overlap_coefficients table.  The number times analyze_overlap is called defined by the core_count variable,
#' the default value is 4.  If a file_output value is provided the the file
#'is appended to with process information messages, otherwise the messages will be sent as the return value
#'once all values are calculated and saved.
#'
#'`process_overlap` calculates the overlap coefficient of peptides between all organisms.
#'
#'@param conn database connection values to create a MySQL connection
#'@param core_count This is to total number cores to be used during parallel processing
#'      it should be no greater than 1/2 of total cores
#'@param split_size This is size of list that should be passed to each execution of
#'      analyze_strong_count.
#'@param start_index the minimum organism_id to start processing at, this can be used
#'      for times when this method fails while processing to allow it to continue
#'      where it left off
#'@param file_output the name of the file to output all messages to, if not provided
#'      the return value will be the debug output
#'
#'@return T or debug output if no file_output was provided
#'
#'@importFrom DBI sqlInterpolate dbGetQuery dbConnect dbDisconnect
#'@importFrom RMariaDB MariaDB
#'@importFrom parallel parLapply makeCluster clusterEvalQ clusterExport stopCluster
#'
#'@author Dustin Crockett
#'
#'@export
process_overlap <- function(conn, core_count = 2, split_size=10, start_index=1, file_output="") {
  start_time <- Sys.time()


  #validate the conn list
  # verify that the conn is a list
  assertthat::assert_that(is.list(conn),
                          msg = "conn is not a list. Make sure conn is a list.")
  # verify that conn has the correct fields
  assertthat::assert_that("dbname" %in% names(conn),
                          msg = "dbname is missing from the list conn")
  assertthat::assert_that("host" %in% names(conn),
                          msg = "host is missing from the list conn")
  assertthat::assert_that("port" %in% names(conn),
                          msg = "port is missing from the list conn")
  assertthat::assert_that("user" %in% names(conn),
                          msg = "user is missing from the list conn")
  assertthat::assert_that("password" %in% names(conn),
                          msg = "password is missing from the list conn")

  con1 <- DBI::dbConnect(RMariaDB::MariaDB(),
                    dbname = conn$dbname,
                    host = conn$host,
                    port = conn$port,
                    user = conn$user,
                    password = conn$password)

  #calculate overlap coefficient
  sqlcmd <- DBI::sqlInterpolate(con1, "select id from candidate.organisms where id >= ?org_id order by id asc", org_id = start_index)
  #sqlcmd <- sqlInterpolate(con1, "select id from candidate.organisms where id >= ?org_id order by peptide_count desc", org_id = start_index)
  results <- DBI::dbGetQuery(con1, sqlcmd)

  DBI::dbDisconnect(con1)

  id_list <- split(results$id, rep(1:ceiling(length(results$id)/split_size), each=split_size)[1:length(results$id)])

  cl <- makeCluster(core_count)

  clusterEvalQ(cl, {
    ## set up each worker.  Could also use clusterExport()
    library(DBI)
    library(RMariaDB)
    NULL
  })
  #print(paste0("range ", range_test))
  #clusterExport(cl, varlist=c("conn","file_output"), envir=environment())
  full_result <- parLapply("cl"=cl, "X" = id_list, "fun" = analyze_overlap, conn=conn, file_output=file_output, chunk.size = 1)

  end_time = Sys.time()
  diff_time <- format(as.numeric(end_time, units = "secs") - as.numeric(start_time, units = "secs"))
  lapply(full_result,cat)

  cat(paste0("Populated overlap_coefficient for ", length(results$id), " organisms, started at ", start_time, ", and finished at ", end_time, ", took a total duration of ", diff_time, " seconds\n"))

  stopCluster(cl)

}

#'Executes multiple steps to optimize the database performance.  First the count of organism
#'for each peptide is calculated and saved to each peptide.  After that indexes are created
#'top improve query performance for sample processing.  Processing message are sent to
#'console out.
#'
#'`optimize_database` Executes multiple optimizations to improve database performance.
#'
#'@param conn database connection values to create a MySQL connection
#'
#'@return T
#'
#'@importFrom assertthat assert_that
#'@importFrom DBI sqlInterpolate dbGetQuery dbConnect dbDisconnect
#'@importFrom RMariaDB MariaDB
#'
#'@author Dustin Crockett
#'
#'@export
optimize_database <- function(conn) {
  start_time <- Sys.time()

  #validate the conn list
  # verify that the conn is a list
  assertthat::assert_that(is.list(conn),
                          msg = "conn is not a list. Make sure conn is a list.")
  # verify that conn has the correct fields
  assertthat::assert_that("dbname" %in% names(conn),
                          msg = "dbname is missing from the list conn")
  assertthat::assert_that("host" %in% names(conn),
                          msg = "host is missing from the list conn")
  assertthat::assert_that("port" %in% names(conn),
                          msg = "port is missing from the list conn")
  assertthat::assert_that("user" %in% names(conn),
                          msg = "user is missing from the list conn")
  assertthat::assert_that("password" %in% names(conn),
                          msg = "password is missing from the list conn")

  con <- DBI::dbConnect(RMariaDB::MariaDB(),
                   dbname = conn$dbname,
                   host = conn$host,
                   port = conn$port,
                   user = conn$user,
                   password = conn$password)

  #before we build the indexes lets create the count of organisms tabel
  DBI::dbExecute(con, 'create table candidate.org_count_temp(peptide_id int unsigned primary key,
				organism_count int2 unsigned not null)')

  DBI::dbExecute(con, 'insert into candidate.org_count_temp(peptide_id, organism_count)
	      select peptide_id, count(organism_id) org_count from candidate.organisms_to_peptides otp group by peptide_id')

  DBI::dbExecute(con, 'update candidate.peptides p
	      inner join candidate.org_count_temp oc on p.id = oc.peptide_id
        set p.organism_count = oc.organism_count')

  DBI::dbExecute(con, 'drop table candidate.org_count_temp')


  #build the index for the peptides table
  #dbExecute(con, 'CREATE INDEX `peptides_id_mass_IDX` USING BTREE ON candidate.peptides (id,mass)')


  #end_time <- Sys.time()
  #diff_time <- format(as.numeric(end_time, units = "secs") - as.numeric(start_time, units = "secs"))
  #print(paste0("Created index for peptides table, started at ", start_time, ", and finished at ", end_time, ", took a total duration of ", diff_time, " seconds"))
  #start_time <- end_time

  #build the index for the peptide_map table
  DBI::dbExecute(con, 'CREATE INDEX `peptide_map_peptide_tag_id_IDX` USING BTREE ON candidate.peptide_map (peptide_tag_id,mass,peptide_id)')

  end_time <- Sys.time()
  diff_time <- format(as.numeric(end_time, units = "secs") - as.numeric(start_time, units = "secs"))
  cat(paste0("Created index for peptide_map table, started at ", start_time, ", and finished at ", end_time, ", took a total duration of ", diff_time, " seconds\n"))

  DBI::dbDisconnect(con)
  return(T)
}


#'This method is executed after the Kegg database is fully loaded.  This method populates
#'taxon information into the database in adds taxon ids for each organism
#'A lineage table is also loaded that provides a full parent lineage for a taxon id
#'
#'`populate_taxon` Populates taxon information into a fully populated database.
#'
#'@param conn database connection values to create a MySQL connection
#'@param all_names a dataframe of all taxon names
#'@param all_nodes a dataframe of all taxons
#'@param kegg_org_taxon a dataframe with the taxon id for each organism in kegg
#'@param lineage_table a dataframe of the entire lineage for each taxon id
#'
#'@return T
#'
#'@importFrom assertthat assert_that
#'@importFrom DBI dbWriteTable dbExecute dbConnect dbDisconnect
#'@importFrom RMariaDB MariaDB
#'
#'@author Dustin Crockett
#'
#'@export
populate_taxon <- function(conn, all_names, all_nodes, kegg_org_taxon, lineage_table) {
  cat("============Populating taxon information============\n")
  begin_time <- Sys.time()
  start_time <- begin_time

  #validate the conn list
  # verify that the conn is a list
  assertthat::assert_that(is.list(conn),
                          msg = "conn is not a list. Make sure conn is a list.")
  # verify that conn has the correct fields
  assertthat::assert_that("dbname" %in% names(conn),
                          msg = "dbname is missing from the list conn")
  assertthat::assert_that("host" %in% names(conn),
                          msg = "host is missing from the list conn")
  assertthat::assert_that("port" %in% names(conn),
                          msg = "port is missing from the list conn")
  assertthat::assert_that("user" %in% names(conn),
                          msg = "user is missing from the list conn")
  assertthat::assert_that("password" %in% names(conn),
                          msg = "password is missing from the list conn")



  # verify that input values are dataframes has the correct fields
  assertthat::assert_that(is.data.frame(all_names),
                          msg = "all_names is not a dataframe")
  assertthat::assert_that(is.data.frame(all_nodes),
                          msg = "all_nodes is not a dataframe")
  assertthat::assert_that(is.data.frame(kegg_org_taxon),
                          msg = "kegg_org_taxon is not a dataframe")
  assertthat::assert_that(is.data.frame(lineage_table),
                          msg = "lineage_table is not a dataframe")


  #verify that the data frame all_names has the correct columns
  assertthat::assert_that("taxon_id" %in% colnames(all_names),
                          msg = "taxon_id column missing from all_names")
  assertthat::assert_that("name_txt" %in% colnames(all_names),
                          msg = "name_txt column missing from all_names")
  assertthat::assert_that("unique_name" %in% colnames(all_names),
                          msg = "unique_name column missing from all_names")
  assertthat::assert_that("name_class" %in% colnames(all_names),
                          msg = "name_class column missing from all_names")

  #verify that the data frame all_nodes has the correct columns
  assertthat::assert_that("taxon_id" %in% colnames(all_nodes),
                          msg = "taxon_id column missing from all_nodes")
  assertthat::assert_that("parent_taxon_id" %in% colnames(all_nodes),
                          msg = "parent_taxon_id column missing from all_nodes")
  assertthat::assert_that("rank" %in% colnames(all_nodes),
                          msg = "rank column missing from all_nodes")
  assertthat::assert_that("embl_code" %in% colnames(all_nodes),
                          msg = "embl_code column missing from all_nodes")
  assertthat::assert_that("division_id" %in% colnames(all_nodes),
                          msg = "division_id column missing from all_nodes")
  assertthat::assert_that("inherited_div_flag" %in% colnames(all_nodes),
                          msg = "inherited_div_flag column missing from all_nodes")
  assertthat::assert_that("genetic_code_id" %in% colnames(all_nodes),
                          msg = "genetic_code_id column missing from all_nodes")
  assertthat::assert_that("inherited_GC_flag" %in% colnames(all_nodes),
                          msg = "inherited_GC_flag column missing from all_nodes")
  assertthat::assert_that("mitochondrial_genetic_code_id" %in% colnames(all_nodes),
                          msg = "mitochondrial_genetic_code_id column missing from all_nodes")
  assertthat::assert_that("inherited_MGC_flag" %in% colnames(all_nodes),
                          msg = "inherited_MGC_flag column missing from all_nodes")
  assertthat::assert_that("GenBank_hidden_flag" %in% colnames(all_nodes),
                          msg = "GenBank_hidden_flag column missing from all_nodes")
  assertthat::assert_that("hidden_subtree_root_flag" %in% colnames(all_nodes),
                          msg = "hidden_subtree_root_flag column missing from all_nodes")
  assertthat::assert_that("comments" %in% colnames(all_nodes),
                          msg = "comments column missing from all_nodes")
  assertthat::assert_that("plastid_genetic_code_id" %in% colnames(all_nodes),
                          msg = "plastid_genetic_code_id column missing from all_nodes")
  assertthat::assert_that("inherited_PGC_flag" %in% colnames(all_nodes),
                          msg = "inherited_PGC_flag column missing from all_nodes")
  assertthat::assert_that("specified_species" %in% colnames(all_nodes),
                          msg = "specified_species column missing from all_nodes")
  assertthat::assert_that("hydrogenosome_genetic_code_id" %in% colnames(all_nodes),
                          msg = "hydrogenosome_gentic_code_id column missing from all_nodes")
  assertthat::assert_that("inherited_HCG_flag" %in% colnames(all_nodes),
                          msg = "inherited_HCG_flag column missing from all_nodes")

  #verify that the data frame kegg_org_taxon has the correct columns
  assertthat::assert_that("Org_code" %in% colnames(kegg_org_taxon),
                          msg = "Org_code column missing from kegg_org_taxon")
  assertthat::assert_that("taxon_id" %in% colnames(kegg_org_taxon),
                          msg = "taxon_id column missing from kegg_org_taxon")

  #verify that the data frame lineage_table has the correct columns
  assertthat::assert_that("node_taxon_id" %in% colnames(lineage_table),
                          msg = "node_taxon_id column missing from lineage_table")
  assertthat::assert_that("node_tax_name" %in% colnames(lineage_table),
                          msg = "node_tax_name column missing from lineage_table")
  assertthat::assert_that("node_rank" %in% colnames(lineage_table),
                          msg = "node_rank column missing from lineage_table")
  assertthat::assert_that("superkingdom" %in% colnames(lineage_table),
                          msg = "superkingdom column missing from lineage_table")
  assertthat::assert_that("superkingdom_name" %in% colnames(lineage_table),
                          msg = "superkingdom_name column missing from lineage_table")
  assertthat::assert_that("kingdom" %in% colnames(lineage_table),
                          msg = "kingdom column missing from lineage_table")
  assertthat::assert_that("kingdom_name" %in% colnames(lineage_table),
                          msg = "kingdom_name column missing from lineage_table")
  assertthat::assert_that("superphylum" %in% colnames(lineage_table),
                          msg = "superphylum column missing from lineage_table")
  assertthat::assert_that("superphylum_name" %in% colnames(lineage_table),
                          msg = "superphylum_name column missing from lineage_table")
  assertthat::assert_that("phylum" %in% colnames(lineage_table),
                          msg = "phylum column missing from lineage_table")
  assertthat::assert_that("phylum_name" %in% colnames(lineage_table),
                          msg = "phylum_name column missing from lineage_table")
  assertthat::assert_that("subphylum" %in% colnames(lineage_table),
                          msg = "subphylum column missing from lineage_table")
  assertthat::assert_that("subphylum_name" %in% colnames(lineage_table),
                          msg = "subphylum_name column missing from lineage_table")
  assertthat::assert_that("superclass" %in% colnames(lineage_table),
                          msg = "superclass column missing from lineage_table")
  assertthat::assert_that("superclass_name" %in% colnames(lineage_table),
                          msg = "superclass_name column missing from lineage_table")
  assertthat::assert_that("class" %in% colnames(lineage_table),
                          msg = "class column missing from lineage_table")
  assertthat::assert_that("class_name" %in% colnames(lineage_table),
                          msg = "class_name column missing from lineage_table")
  assertthat::assert_that("subclass" %in% colnames(lineage_table),
                          msg = "subclass column missing from lineage_table")
  assertthat::assert_that("subclass_name" %in% colnames(lineage_table),
                          msg = "subclass_name column missing from lineage_table")
  assertthat::assert_that("infraclass" %in% colnames(lineage_table),
                          msg = "infraclass column missing from lineage_table")
  assertthat::assert_that("infraclass_name" %in% colnames(lineage_table),
                          msg = "infraclass_name column missing from lineage_table")
  assertthat::assert_that("cohort" %in% colnames(lineage_table),
                          msg = "cohort column missing from lineage_table")
  assertthat::assert_that("cohort_name" %in% colnames(lineage_table),
                          msg = "cohort_name column missing from lineage_table")
  assertthat::assert_that("subcohort" %in% colnames(lineage_table),
                          msg = "subcohort column missing from lineage_table")
  assertthat::assert_that("subcohort_name" %in% colnames(lineage_table),
                          msg = "subcohort_name column missing from lineage_table")
  assertthat::assert_that("superorder" %in% colnames(lineage_table),
                          msg = "superorder column missing from lineage_table")
  assertthat::assert_that("superorder_name" %in% colnames(lineage_table),
                          msg = "superorder_name column missing from lineage_table")
  assertthat::assert_that("order" %in% colnames(lineage_table),
                          msg = "order column missing from lineage_table")
  assertthat::assert_that("order_name" %in% colnames(lineage_table),
                          msg = "order_name column missing from lineage_table")
  assertthat::assert_that("suborder" %in% colnames(lineage_table),
                          msg = "suborder column missing from lineage_table")
  assertthat::assert_that("suborder_name" %in% colnames(lineage_table),
                          msg = "suborder_name column missing from lineage_table")
  assertthat::assert_that("infraorder" %in% colnames(lineage_table),
                          msg = "infraorder column missing from lineage_table")
  assertthat::assert_that("infraorder_name" %in% colnames(lineage_table),
                          msg = "infraorder_name column missing from lineage_table")
  assertthat::assert_that("superfamily" %in% colnames(lineage_table),
                          msg = "superfamily column missing from lineage_table")
  assertthat::assert_that("superfamily_name" %in% colnames(lineage_table),
                          msg = "superfamily_name column missing from lineage_table")
  assertthat::assert_that("family" %in% colnames(lineage_table),
                          msg = "family column missing from lineage_table")
  assertthat::assert_that("family_name" %in% colnames(lineage_table),
                          msg = "family_name column missing from lineage_table")
  assertthat::assert_that("subfamily" %in% colnames(lineage_table),
                          msg = "subfamily column missing from lineage_table")
  assertthat::assert_that("subfamily_name" %in% colnames(lineage_table),
                          msg = "subfamily_name column missing from lineage_table")
  assertthat::assert_that("tribe" %in% colnames(lineage_table),
                          msg = "tribe column missing from lineage_table")
  assertthat::assert_that("tribe_name" %in% colnames(lineage_table),
                          msg = "tribe_name column missing from lineage_table")
  assertthat::assert_that("subtribe" %in% colnames(lineage_table),
                          msg = "subtribe column missing from lineage_table")
  assertthat::assert_that("subtribe_name" %in% colnames(lineage_table),
                          msg = "subtribe_name column missing from lineage_table")
  assertthat::assert_that("genus" %in% colnames(lineage_table),
                          msg = "genus column missing from lineage_table")
  assertthat::assert_that("genus_name" %in% colnames(lineage_table),
                          msg = "genus_name column missing from lineage_table")
  assertthat::assert_that("subgenus" %in% colnames(lineage_table),
                          msg = "subgenus column missing from lineage_table")
  assertthat::assert_that("subgenus_name" %in% colnames(lineage_table),
                          msg = "subgenus_name column missing from lineage_table")
  assertthat::assert_that("section" %in% colnames(lineage_table),
                          msg = "section column missing from lineage_table")
  assertthat::assert_that("section_name" %in% colnames(lineage_table),
                          msg = "section_name column missing from lineage_table")
  assertthat::assert_that("subsection" %in% colnames(lineage_table),
                          msg = "subsection column missing from lineage_table")
  assertthat::assert_that("subsection_name" %in% colnames(lineage_table),
                          msg = "subsection_name column missing from lineage_table")
  assertthat::assert_that("series" %in% colnames(lineage_table),
                          msg = "series column missing from lineage_table")
  assertthat::assert_that("series_name" %in% colnames(lineage_table),
                          msg = "series_name column missing from lineage_table")
  assertthat::assert_that("species_group" %in% colnames(lineage_table),
                          msg = "species_group column missing from lineage_table")
  assertthat::assert_that("species_group_name" %in% colnames(lineage_table),
                          msg = "species_group_name column missing from lineage_table")
  assertthat::assert_that("species_subgroup" %in% colnames(lineage_table),
                          msg = "species_subgroup column missing from lineage_table")
  assertthat::assert_that("species_subgroup_name" %in% colnames(lineage_table),
                          msg = "species_subgroup_name column missing from lineage_table")
  assertthat::assert_that("species" %in% colnames(lineage_table),
                          msg = "species column missing from lineage_table")
  assertthat::assert_that("species_name" %in% colnames(lineage_table),
                          msg = "species_name column missing from lineage_table")
  assertthat::assert_that("subspecies" %in% colnames(lineage_table),
                          msg = "subspecies column missing from lineage_table")
  assertthat::assert_that("subspecies_name" %in% colnames(lineage_table),
                          msg = "subspecies_name column missing from lineage_table")
  assertthat::assert_that("varietas" %in% colnames(lineage_table),
                          msg = "varietas column missing from lineage_table")
  assertthat::assert_that("varietas_name" %in% colnames(lineage_table),
                          msg = "varietas_name column missing from lineage_table")
  assertthat::assert_that("forma" %in% colnames(lineage_table),
                          msg = "forma column missing from lineage_table")
  assertthat::assert_that("forma_name" %in% colnames(lineage_table),
                          msg = "forma_name column missing from lineage_table")

  con <- DBI::dbConnect(RMariaDB::MariaDB(),
                   dbname = conn$dbname,
                   host = conn$host,
                   port = conn$port,
                   user = conn$user,
                   password = conn$password)
  cat("Loading all_names data\n")

  #With the data validated, first we upload all of the data into temporary tables
  DBI::dbWriteTable(
    conn = con,
    DBI::Id(schema="candidate",table="upload_all_names"),
    value = all_names,
    overwrite = T,
    temporary = T,
  )
  end_time <- Sys.time()
  diff_time <- format(as.numeric(end_time, units = "secs") - as.numeric(start_time, units = "secs"))
  cat(paste0("Finished uploading all_names ", start_time, ", and finished at ", end_time, ", took a total duration of ", diff_time, " seconds, starting all_nodes\n"))
  start_time <- end_time

  DBI::dbWriteTable(
    conn = con,
    DBI::Id(schema="candidate",table="upload_all_nodes"),
    value = all_nodes,
    overwrite = T,
    temporary = T,
  )

  end_time <- Sys.time()
  diff_time <- format(as.numeric(end_time, units = "secs") - as.numeric(start_time, units = "secs"))
  cat(paste0("Finished uploading all_nodes ", start_time, ", and finished at ", end_time, ", took a total duration of ", diff_time, " seconds, starting kegg_org_taxon\n"))
  start_time <- end_time

  DBI::dbWriteTable(
    conn = con,
    DBI::Id(schema="candidate",table="upload_kegg_org_taxon"),
    value = kegg_org_taxon,
    overwrite = T,
    temporary = T,
  )

  end_time <- Sys.time()
  diff_time <- format(as.numeric(end_time, units = "secs") - as.numeric(start_time, units = "secs"))
  cat(paste0("Finished uploading kegg_org_taxon ", start_time, ", and finished at ", end_time, ", took a total duration of ", diff_time, " seconds, starting lineage_table\n"))
  start_time <- end_time

  DBI::dbWriteTable(
    conn = con,
    DBI::Id(schema="candidate",table="upload_lineage_table"),
    value = lineage_table,
    overwrite = T,
    temporary = T,
  )

  end_time <- Sys.time()
  diff_time <- format(as.numeric(end_time, units = "secs") - as.numeric(start_time, units = "secs"))
  cat(paste0("Finished uploading lineage_table ", start_time, ", and finished at ", end_time, ", took a total duration of ", diff_time, " seconds, starting taxon population\n"))
  start_time <- end_time

  #next we migrate the data into properly named and indexed tables
  DBI::dbExecute(con, 'insert into candidate.taxons (taxon_id, parent_taxon_id, `rank`, embl_code, division_id , inherited_div_flag,genetic_code_id,inherited_Gc_flag,
			mitochondrial_genetic_code_id,inherited_MGC_flag,GenBank_hidden_flag,hidden_subtree_root_flag,comments,plastid_genetic_code_id,
			inherited_PGC_flag,specified_species,hydrogenosome_genetic_code_id,inherited_HCG_flag)
		select taxon_id, parent_taxon_id, `rank`, embl_code, division_id , inherited_div_flag,genetic_code_id,inherited_Gc_flag,
			mitochondrial_genetic_code_id,inherited_MGC_flag,GenBank_hidden_flag,hidden_subtree_root_flag,comments,plastid_genetic_code_id,
			inherited_PGC_flag,specified_species,hydrogenosome_genetic_code_id,inherited_HCG_flag from candidate.upload_all_nodes')

  end_time <- Sys.time()
  diff_time <- format(as.numeric(end_time, units = "secs") - as.numeric(start_time, units = "secs"))
  cat(paste0("Finished populating taxon ", start_time, ", and finished at ", end_time, ", took a total duration of ", diff_time, " seconds, starting taxon_names population\n"))
  start_time <- end_time

  DBI::dbExecute(con, 'insert into candidate.taxon_names(taxon_id, name_txt, unique_name, name_class)
	select taxon_id, name_txt, unique_name, name_class from candidate.upload_all_names ')

  end_time <- Sys.time()
  diff_time <- format(as.numeric(end_time, units = "secs") - as.numeric(start_time, units = "secs"))
  cat(paste0("Finished populating taxon_names ", start_time, ", and finished at ", end_time, ", took a total duration of ", diff_time, " seconds, starting taxon_lineages population\n"))
  start_time <- end_time

  DBI::dbExecute(con, 'insert into candidate.taxon_lineages (taxon_id, taxon_name, taxon_rank,superkingdom,kingdom,subkingdom,superphylum,phylum,subphylum ,
            superclass ,class , subclass ,infraclass ,cohort,superorder,`order`,suborder,infraorder,parvorder,superfamily,
            family,subfamily, tribe,subtribe,genus,subgenus,`section`,subsection,series,species_group,species_subgroup, species,subspecies,
            varietas,forma,superkingdom_name,kingdom_name,subkingdom_name,superphylum_name,phylum_name,subphylum_name ,
            superclass_name ,class_name , subclass_name ,infraclass_name ,cohort_name,superorder_name,order_name,suborder_name,infraorder_name,parvorder_name,
            superfamily_name,family_name,subfamily_name, tribe_name,subtribe_name,genus_name,subgenus_name,section_name,subsection_name,series_name,
            species_group_name,species_subgroup_name, species_name,subspecies_name,varietas_name,forma_name)
select node_taxon_id, node_tax_name, node_rank,superkingdom,kingdom,subkingdom,superphylum,phylum,subphylum ,
            superclass ,class , subclass ,infraclass ,cohort,superorder,`order`,suborder,infraorder,parvorder,superfamily,
            family,subfamily, tribe,subtribe,genus,subgenus,`section`,subsection,series,species_group,species_subgroup, species,subspecies,
            varietas,forma,superkingdom_name,kingdom_name,subkingdom_name,superphylum_name,phylum_name,subphylum_name ,
            superclass_name ,class_name , subclass_name ,infraclass_name ,cohort_name,superorder_name,order_name,suborder_name,infraorder_name,parvorder_name,
            superfamily_name,family_name,subfamily_name, tribe_name,subtribe_name,genus_name,subgenus_name,section_name,subsection_name,series_name,
            species_group_name,species_subgroup_name, species_name,subspecies_name,varietas_name,forma_name from candidate.upload_lineage_table ')

  end_time <- Sys.time()
  diff_time <- format(as.numeric(end_time, units = "secs") - as.numeric(start_time, units = "secs"))
  cat(paste0("Finished populating taxon_lineages ", start_time, ", and finished at ", end_time, ", took a total duration of ", diff_time, " seconds, starting organism population\n"))
  start_time <- end_time

  #now we update the organism table with a foreign key to the taxon_id table
  DBI::dbExecute(con, 'update candidate.organisms o
    	join candidate.upload_kegg_org_taxon ukt on ukt.org_code = o.kegg_org_code
    	set o.taxon_id = ukt.taxon_id ')

  end_time <- Sys.time()
  diff_time <- format(as.numeric(end_time, units = "secs") - as.numeric(start_time, units = "secs"))
  cat(paste0("Finished populating organisms ", start_time, ", and finished at ", end_time, ", took a total duration of ", diff_time, " seconds\n"))

  #finally lets clean up the database connection
  DBI::dbDisconnect(con)

  diff_time <- format(as.numeric(end_time, units = "secs") - as.numeric(begin_time, units = "secs"))
  cat(paste0("====Taxon population, started at ", start_time, ", and finished at ", end_time, ", took a total duration of ", diff_time, " seconds====\n"))

  return(T)
}


#'This method executes all stages of the building the database.  Including deleting the existing
#'database, building the data model, populating all kegg information and performing the post
#'upload steps.
#'
#'`build_database` Goes through all steps of build the database with Kegg data.
#'
#'@param conn database connection values to create a MySQL connection
#'@param file_location The location of the rData organism files
#'@param log_filename The location and file name of the log file
#'@param large_storage_found when True use the large_storage location for peptide_map when
#' false place peptide map with the rest of the database
#'@param large_storage The storage location of the large storage
#'@param max_peptide_length the maximum character length of peptides to be imported
#'@param core_count This is to total number cores to be used during parallel processing
#'      it should be no greater than 1/2 of total cores
#'@param split_size This is size of list that should be passed to each execution of
#'      analyze_strong_count.
#'@param strong_tolerance the percentage difference between organism coverages within a genus
#'      of the two highest covered genus, for the highest covered genus to be
#'      have a strong peptide
#'@param max_count Starting with 1 how many more organisms to process into the database
#'
#'@return T
#'
#'@importFrom assertthat assert_that
#'@importFrom DBI dbWriteTable dbExecute dbConnect dbDisconnect
#'@importFrom RMariaDB MariaDB
#'@importFrom stats setNames
#'
#'@author Dustin Crockett
#'
#'@export
build_database <- function(conn, file_location, log_filename="initdb.log",large_storage_found=F, large_storage="", max_peptide_length=250, core_count=2, split_size=10, strong_tolerance=0.053, max_count = 0) {

  #assign the log_file variable with the log file
  log_file <- file(log_filename, open = "at")
  #assign the standard IO to the log_file
  sink(log_file)

  cat("==========================Starting Build Database===============================\n")

  files <- list.files(file_location, pattern="*.RData") %>% stats::setNames(c('Filename'))

  cat(paste0("Processed files in '", file_location, "', found ", length(files), " RData files\n"))
  begin_time <- Sys.time()
  start_time <- begin_time

  delete_database(conn,T)

  end_time <- Sys.time()
  diff_time <- format(as.numeric(end_time, units = "secs") - as.numeric(start_time, units = "secs"))
  cat(paste0("Deleted the existing database, started at ", start_time, ", and finished at ", end_time, ", took a total duration of ", diff_time, " seconds\n"))
  start_time <- end_time

  create_datamodel(conn= conn,large_storage_found = large_storage_found, large_storage = large_storage, max_peptide_length = max_peptide_length)

  end_time <- Sys.time()
  diff_time <- format(as.numeric(end_time, units = "secs") - as.numeric(start_time, units = "secs"))
  cat(paste0("Created the new database datamodel, started at ", start_time, ", and finished at ", end_time, ", took a total duration of ", diff_time, " seconds\n"))
  start_time <- end_time

  cat("==========================Starting Organism Population===============================\n")

  process_one_file <- function(files, max_peptide_length) {
    # change \\ to / for linux
    #objectName <- load(paste0(file_location,"\\", files))
    objectName <- load(paste0(file_location,"/", files))
    if(objectName == "organism_info") {
      out <- tryCatch({
        withCallingHandlers(populate_organism(conn,organism_info,max_peptide_length = max_peptide_length)
                            ,error=function(e) {print(sys.calls())}
                            ,warning=function(w) {print(sys.calls())
                              invokeRestart("muffleWarning")}
        )
      },
      error = function(m) { print(m) }
      )
    } else {
      #the organism information might be named something different lets try anyways
      Organism <- get(objectName)
      out <- tryCatch({
        withCallingHandlers(populate_organism(conn,Organism)
                            ,error=function(e) {print(sys.calls())}
                            ,warning=function(w) {print(sys.calls())
                              invokeRestart("muffleWarning")}
        )
      },
      error = function(m) { print(m) }
      )
    }
  }

  if(max_count == 0 | max_count >= length(files)) {
    tmp <- lapply(files[1:length(files)], process_one_file, max_peptide_length = max_peptide_length)

    end_time <- Sys.time()
    diff_time <- format(as.numeric(end_time, units = "secs") - as.numeric(start_time, units = "secs"))
    cat(paste0("Populated ",length(files), " organisms into the database, started at ", start_time, ", and finished at ", end_time, ", took a total duration of ", diff_time, " seconds\n"))
  } else {
    tmp <- lapply(files[1:max_count], process_one_file, max_peptide_length = max_peptide_length)

    end_time <- Sys.time()
    diff_time <- format(as.numeric(end_time, units = "secs") - as.numeric(start_time, units = "secs"))
    cat(paste0("Populated ",max_count, " organisms into the database, started at ", start_time, ", and finished at ", end_time, ", took a total duration of ", diff_time, " seconds\n"))
  }

  start_time <- end_time

  cat("==========================Starting Data Analysis===============================\n")

  out <- tryCatch({
    withCallingHandlers(process_strong(conn, core_count = core_count, split_size = split_size, tolerance = strong_tolerance)
                        ,error=function(e) {print(sys.calls())}
                        ,warning=function(w) {print(sys.calls())
                          invokeRestart("muffleWarning")}
    )
  },
  error = function(m) { print(m) }
  )
  end_time <- Sys.time()
  diff_time <- format(as.numeric(end_time, units = "secs") - as.numeric(start_time, units = "secs"))
  cat(paste0("Generated strong peptide data, started at ", start_time, ", and finished at ", end_time, ", took a total duration of ", diff_time, " seconds\n"))
  start_time <- end_time


  out <- tryCatch({
    withCallingHandlers(process_overlap(conn,core_count = core_count, split_size = split_size, file_output = log_filename)
                        ,error=function(e) {print(sys.calls())}
                        ,warning=function(w) {print(sys.calls())
                          invokeRestart("muffleWarning")}
    )
  },
  error = function(m) { print(m) }
  )
  end_time <- Sys.time()
  diff_time <- format(as.numeric(end_time, units = "secs") - as.numeric(start_time, units = "secs"))
  cat(paste0("Generated overlap coefficient data, started at ", start_time, ", and finished at ", end_time, ", took a total duration of ", diff_time, " seconds\n"))
  start_time <- end_time


  out <- tryCatch({
    withCallingHandlers(optimize_database(conn)
                        ,error=function(e) {print(sys.calls())}
                        ,warning=function(w) {print(sys.calls())
                          invokeRestart("muffleWarning")}
    )
  },
  error = function(m) { print(m) }
  )
  end_time <- Sys.time()
  diff_time <- format(as.numeric(end_time, units = "secs") - as.numeric(start_time, units = "secs"))
  cat(paste0("Optimized the database, started at ", start_time, ", and finished at ", end_time, ", took a total duration of ", diff_time, " seconds\n"))



  diff_time <- format(as.numeric(end_time, units = "secs") - as.numeric(begin_time, units = "secs"))
  cat(paste0("====Full Build of database, started at ", start_time, ", and finished at ", end_time, ", took a total duration of ", diff_time, " seconds====\n"))


  #return the standard io back to normal
  sink()
  close(log_file)
}

#'Returns information about all organisms in the database
#'
#'`organism_info` Returns the sample_Id and peptide_tag for each sample in a given sample set.
#'
#'@param conn database connection values to create a MySQL connection
#'
#'@return a data.frame of , this is to be used to pivot other dataframes into a matrix
#'@importFrom assertthat assert_that
#'@importFrom DBI dbGetQuery dbDisconnect dbConnect
#'@importFrom RMariaDB MariaDB
#'
#' @author Dustin Crockett
#'
#'@export
organism_info <- function(conn) {

  #validate the conn list
  # verify that the conn is a list
  assertthat::assert_that(is.list(conn),
                          msg = "conn is not a list. Make sure conn is a list.")
  # verify that conn has the correct fields
  assertthat::assert_that("dbname" %in% names(conn),
                          msg = "dbname is missing from the list conn")
  assertthat::assert_that("host" %in% names(conn),
                          msg = "host is missing from the list conn")
  assertthat::assert_that("port" %in% names(conn),
                          msg = "port is missing from the list conn")
  assertthat::assert_that("user" %in% names(conn),
                          msg = "user is missing from the list conn")
  assertthat::assert_that("password" %in% names(conn),
                          msg = "password is missing from the list conn")

  con <- DBI::dbConnect(RMariaDB::MariaDB(),
                   dbname = conn$dbname,
                   host = conn$host,
                   port = conn$port,
                   user = conn$user,
                   password = conn$password)

  #retrieve information about all organisms in the database
  results <- DBI::dbGetQuery(con, "select o.id organism_id, o.kegg_id, o.kegg_org_code, o.name organism_name, s.name species_name, g.name genus_name, o.peptide_count, o.protein_count, o.strong_peptide_count
                            	from candidate.organisms o
                                  join candidate.species s on o.species_id = s.id
                                  join candidate.genus g on g.id = s.genus_id")

  #clean up connection
  DBI::dbDisconnect(con)

  return(results)
}


#'Returns the overlap coefficients for all organisms
#'
#'`overlap_coefficients` Returns the overlap coefficients for all organisms.
#'
#'@param conn database connection values to create a MySQL connection
#'
#'@return a data.frame of with a kegg_id and overlap coefficients with all other organisms in matrix form
#'@importFrom assertthat assert_that
#'@importFrom DBI dbExecute dbGetQuery dbDisconnect dbConnect
#'@importFrom RMariaDB MariaDB
#'@importFrom utils read.csv
#' @author Dustin Crockett
#'
#'@export
overlap_coefficients <- function(conn) {

  #validate the conn list
  # verify that the conn is a list
  assertthat::assert_that(is.list(conn),
                          msg = "conn is not a list. Make sure conn is a list.")
  # verify that conn has the correct fields
  assertthat::assert_that("dbname" %in% names(conn),
                          msg = "dbname is missing from the list conn")
  assertthat::assert_that("host" %in% names(conn),
                          msg = "host is missing from the list conn")
  assertthat::assert_that("port" %in% names(conn),
                          msg = "port is missing from the list conn")
  assertthat::assert_that("user" %in% names(conn),
                          msg = "user is missing from the list conn")
  assertthat::assert_that("password" %in% names(conn),
                          msg = "password is missing from the list conn")

  con <- DBI::dbConnect(RMariaDB::MariaDB(),
                   dbname = conn$dbname,
                   host = conn$host,
                   port = conn$port,
                   user = conn$user,
                   password = conn$password)

  #for the query to work with thousands of organisms we first need to update group_concat_max_len
  DBI::dbExecute(con, 'SET SESSION group_concat_max_len = 1000000')

  #for the query to work with thousands of organisms we first need to update group_concat_max_len
  DBI::dbExecute(con, 'SET SESSION collation_connection = latin1_swedish_ci')

  #retrieve all overlap coefficients
  results <- DBI::dbGetQuery(con, "select 'kegg_id' kegg_id, GROUP_CONCAT( o.kegg_id
                                      ORDER BY o.id ASC
                                      SEPARATOR ',') matrix
                                      from organisms o
                              union
                              SELECT
                              	ocj.kegg_id,
                              	GROUP_CONCAT( ocj.coefficient
                                      ORDER BY ocj.organism_id_j ASC
                                      SEPARATOR ',')
                              from
                              	(select o.kegg_id, oc.organism_id_j,  oc.coefficient
                              	from organisms o
                              	join candidate.overlap_coefficient oc on o.id = oc.organism_id_i
                              	union select o2.kegg_id, o2.id, '' coefficient
                              	from organisms o2 ) ocj
                              	group by ocj.kegg_id")

  #clean up connection
  DBI::dbDisconnect(con)

  #let R read database results like a csv file
  #results$kegg_id is a vector of strings with the first string being the column header, and becomes column 1
  #results$matrix will supply the rest of the columns
  output_df <- cbind(
    read.csv(text = results$kegg_id, stringsAsFactors = F),
    read.csv(text = results$matrix, stringsAsFactors = F)
  )

  return(output_df)
}

#'Returns the jaccard index for all organisms
#'
#'`jaccard_index` Returns the jaccard index for all organisms.
#'
#'@param conn database connection values to create a MySQL connection
#'
#'@return a data.frame of with a kegg_id and jaccard indexes with all other organisms in matrix form
#'@importFrom assertthat assert_that
#'@importFrom DBI dbExecute dbGetQuery dbDisconnect dbConnect
#'@importFrom RMariaDB MariaDB
#'@importFrom utils read.csv
#'
#' @author Dustin Crockett
#'
#'@export
jaccard_index <- function(conn) {

  #validate the conn list
  # verify that the conn is a list
  assertthat::assert_that(is.list(conn),
                          msg = "conn is not a list. Make sure conn is a list.")
  # verify that conn has the correct fields
  assertthat::assert_that("dbname" %in% names(conn),
                          msg = "dbname is missing from the list conn")
  assertthat::assert_that("host" %in% names(conn),
                          msg = "host is missing from the list conn")
  assertthat::assert_that("port" %in% names(conn),
                          msg = "port is missing from the list conn")
  assertthat::assert_that("user" %in% names(conn),
                          msg = "user is missing from the list conn")
  assertthat::assert_that("password" %in% names(conn),
                          msg = "password is missing from the list conn")

  con <- DBI::dbConnect(RMariaDB::MariaDB(),
                        dbname = conn$dbname,
                        host = conn$host,
                        port = conn$port,
                        user = conn$user,
                        password = conn$password)

  #for the query to work with thousands of organisms we first need to update group_concat_max_len
  DBI::dbExecute(con, 'SET SESSION group_concat_max_len = 1000000')

  #for the query to work with thousands of organisms we first need to update group_concat_max_len
  DBI::dbExecute(con, 'SET SESSION collation_connection = latin1_swedish_ci')

  #retrieve all jaccard indexes
  results <- DBI::dbGetQuery(con, "select 'kegg_id' kegg_id, GROUP_CONCAT( o.kegg_id
                                      ORDER BY o.id ASC
                                      SEPARATOR ',') matrix
                                      from organisms o
                              union
                              SELECT
                              	ocj.kegg_id,
                              	GROUP_CONCAT( ocj.coefficient
                                      ORDER BY ocj.organism_id_j ASC
                                      SEPARATOR ',')
                              from
                              	(select o.kegg_id, oc.organism_id_j,  oc.jaccard_index coefficient
                              	from organisms o
                              	join candidate.overlap_coefficient oc on o.id = oc.organism_id_i
                              	union select o2.kegg_id, o2.id, '' coefficient
                              	from organisms o2 ) ocj
                              	group by ocj.kegg_id")

  #clean up connection
  DBI::dbDisconnect(con)

  #let R read database results like a csv file
  #results$kegg_id is a vector of strings with the first string being the column header, and becomes column 1
  #results$matrix will supply the rest of the columns
  output_df <- cbind(
    read.csv(text = results$kegg_id, stringsAsFactors = F),
    read.csv(text = results$matrix, stringsAsFactors = F)
  )

  return(output_df)
}

#'Returns the strong peptide overlap coefficients for all organisms
#'
#'`overlap_coefficients_strong` Returns the strong peptide overlap coefficients for all organisms.
#'
#'@param conn database connection values to create a MySQL connection
#'
#'@return a data.frame of with a kegg_id and overlap coefficients for strong peptides with all other organisms in matrix form
#'@importFrom assertthat assert_that
#'@importFrom DBI dbExecute dbGetQuery dbDisconnect dbConnect
#'@importFrom RMariaDB MariaDB
#'@importFrom utils read.csv
#' @author Dustin Crockett
#'
#'@export
overlap_coefficients_strong <- function(conn) {

  #validate the conn list
  # verify that the conn is a list
  assertthat::assert_that(is.list(conn),
                          msg = "conn is not a list. Make sure conn is a list.")
  # verify that conn has the correct fields
  assertthat::assert_that("dbname" %in% names(conn),
                          msg = "dbname is missing from the list conn")
  assertthat::assert_that("host" %in% names(conn),
                          msg = "host is missing from the list conn")
  assertthat::assert_that("port" %in% names(conn),
                          msg = "port is missing from the list conn")
  assertthat::assert_that("user" %in% names(conn),
                          msg = "user is missing from the list conn")
  assertthat::assert_that("password" %in% names(conn),
                          msg = "password is missing from the list conn")

  con <- DBI::dbConnect(RMariaDB::MariaDB(),
                        dbname = conn$dbname,
                        host = conn$host,
                        port = conn$port,
                        user = conn$user,
                        password = conn$password)

  #for the query to work with thousands of organisms we first need to update group_concat_max_len
  DBI::dbExecute(con, 'SET SESSION group_concat_max_len = 1000000')

  #for the query to work with thousands of organisms we first need to update group_concat_max_len
  DBI::dbExecute(con, 'SET SESSION collation_connection = latin1_swedish_ci')

  #retrieve all overlap coefficients
  results <- DBI::dbGetQuery(con, "select 'kegg_id' kegg_id, GROUP_CONCAT( o.kegg_id
                                      ORDER BY o.id ASC
                                      SEPARATOR ',') matrix
                                      from organisms o
                              union
                              SELECT
                              	ocj.kegg_id,
                              	GROUP_CONCAT( ocj.coefficient
                                      ORDER BY ocj.organism_id_j ASC
                                      SEPARATOR ',')
                              from
                              	(select o.kegg_id, oc.organism_id_j,  oc.strong_coefficient coefficient
                              	from organisms o
                              	join candidate.overlap_coefficient oc on o.id = oc.organism_id_i
                              	union select o2.kegg_id, o2.id, '' coefficient
                              	from organisms o2 ) ocj
                              	group by ocj.kegg_id")

  #clean up connection
  DBI::dbDisconnect(con)

  #let R read database results like a csv file
  #results$kegg_id is a vector of strings with the first string being the column header, and becomes column 1
  #results$matrix will supply the rest of the columns
  output_df <- cbind(
    read.csv(text = results$kegg_id, stringsAsFactors = F),
    read.csv(text = results$matrix, stringsAsFactors = F)
  )

  return(output_df)
}

#'Returns the strong peptide jaccard index for all organisms
#'
#'`jaccard_index` Returns the strong peptide jaccard index for all organisms.
#'
#'@param conn database connection values to create a MySQL connection
#'
#'@return a data.frame of with a kegg_id and strong peptide jaccard indexes with all other organisms in matrix form
#'@importFrom assertthat assert_that
#'@importFrom DBI dbExecute dbGetQuery dbDisconnect dbConnect
#'@importFrom RMariaDB MariaDB
#'@importFrom utils read.csv
#' @author Dustin Crockett
#'
#'@export
jaccard_index_strong <- function(conn) {

  #validate the conn list
  # verify that the conn is a list
  assertthat::assert_that(is.list(conn),
                          msg = "conn is not a list. Make sure conn is a list.")
  # verify that conn has the correct fields
  assertthat::assert_that("dbname" %in% names(conn),
                          msg = "dbname is missing from the list conn")
  assertthat::assert_that("host" %in% names(conn),
                          msg = "host is missing from the list conn")
  assertthat::assert_that("port" %in% names(conn),
                          msg = "port is missing from the list conn")
  assertthat::assert_that("user" %in% names(conn),
                          msg = "user is missing from the list conn")
  assertthat::assert_that("password" %in% names(conn),
                          msg = "password is missing from the list conn")

  con <- DBI::dbConnect(RMariaDB::MariaDB(),
                        dbname = conn$dbname,
                        host = conn$host,
                        port = conn$port,
                        user = conn$user,
                        password = conn$password)

  #for the query to work with thousands of organisms we first need to update group_concat_max_len
  DBI::dbExecute(con, 'SET SESSION group_concat_max_len = 1000000')

  #for the query to work with thousands of organisms we first need to update group_concat_max_len
  DBI::dbExecute(con, 'SET SESSION collation_connection = latin1_swedish_ci')

  #retrieve all jaccard indexes
  results <- DBI::dbGetQuery(con, "select 'kegg_id' kegg_id, GROUP_CONCAT( o.kegg_id
                                      ORDER BY o.id ASC
                                      SEPARATOR ',') matrix
                                      from organisms o
                              union
                              SELECT
                              	ocj.kegg_id,
                              	GROUP_CONCAT( ocj.coefficient
                                      ORDER BY ocj.organism_id_j ASC
                                      SEPARATOR ',')
                              from
                              	(select o.kegg_id, oc.organism_id_j,  oc.strong_jaccard_index coefficient
                              	from organisms o
                              	join candidate.overlap_coefficient oc on o.id = oc.organism_id_i
                              	union select o2.kegg_id, o2.id, '' coefficient
                              	from organisms o2 ) ocj
                              	group by ocj.kegg_id")

  #clean up connection
  DBI::dbDisconnect(con)

  #let R read database results like a csv file
  #results$kegg_id is a vector of strings with the first string being the column header, and becomes column 1
  #results$matrix will supply the rest of the columns
  output_df <- cbind(
    read.csv(text = results$kegg_id, stringsAsFactors = F),
    read.csv(text = results$matrix, stringsAsFactors = F)
  )

  return(output_df)
}

## execute the build scripts
# build_database <- function(conn, file_location, log_filename="initdb.log",large_storage_found=F, large_storage="", max_peptide_length=250, core_count=2, split_size=10, strong_tolerance=0.053, max_count = 0) {

initdb <-function() {
build_database( conn=conn_list,
                file_location="data/RData",
                log_filename="log/initdb.log",
                core_count=24)
}

